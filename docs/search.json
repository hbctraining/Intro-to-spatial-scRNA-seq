[
  {
    "objectID": "lessons/01_introduction-to-spatial.html",
    "href": "lessons/01_introduction-to-spatial.html",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial.html#sub-topic-1",
    "href": "lessons/01_introduction-to-spatial.html#sub-topic-1",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial.html#sub-topic-2",
    "href": "lessons/01_introduction-to-spatial.html#sub-topic-2",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial.html#sub-topic-3",
    "href": "lessons/01_introduction-to-spatial.html#sub-topic-3",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial.html#sub-topic-1-1",
    "href": "lessons/01_introduction-to-spatial.html#sub-topic-1-1",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial.html#sub-topic-2-1",
    "href": "lessons/01_introduction-to-spatial.html#sub-topic-2-1",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial.html#sub-topic-3-1",
    "href": "lessons/01_introduction-to-spatial.html#sub-topic-3-1",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial.html#sub-topic-1-2",
    "href": "lessons/01_introduction-to-spatial.html#sub-topic-1-2",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial.html#sub-topic-2-2",
    "href": "lessons/01_introduction-to-spatial.html#sub-topic-2-2",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial.html#sub-topic-3-2",
    "href": "lessons/01_introduction-to-spatial.html#sub-topic-3-2",
    "title": "Introduction to Spatial Single Cell RNA-sequencing",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1:",
      "Introduction to Spatial Single Cell RNA-sequencing"
    ]
  },
  {
    "objectID": "lessons/01_introduction-to-spatial_Answer-key.html",
    "href": "lessons/01_introduction-to-spatial_Answer-key.html",
    "title": "Introduction to Spatial Single Cell RNA-sequencing Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\nIntroduction to Spatial Single-cell RNA-seq\n\n\n\nAudience\nComputational skills required\nDuration\n\n\n\n\nBiologists\nIntroduction to R\n4-session online workshop (~7.5 hours of trainer-led time)\n\n\n\n\nDescription\nThis repository has teaching materials for a hands-on Introduction to Spatial Single-cell RNA-seq workshop. ADD DESCRIPTION HERE STILL Working knowledge of R is required or completion of the Introduction to R workshop.\nNote for Trainers: Please note that the schedule linked below assumes that learners will spend between 3-4 hours on reading through, and completing exercises from selected lessons between classes. The online component of the workshop focuses on more exercises and discussion/Q & A.\n\n\n\n\n\n\nNote\n\n\n\nThese materials were developed for a trainer-led workshop, but are also amenable to self-guided learning.\n\n\n\n\nLearning Objectives\n\nLO 1\nLO 2\nLO 3\nLO 4\n\n\n\nLessons\n\nWorkshop schedule (trainer-led learning)\nSelf-learning\n\n\n\nInstallation Requirements\n\nApplications\nDownload the most recent versions of R and RStudio for your laptop:\n\nR (version 4.0.0 or above)\nRStudio\n\n\n\nPackages for R\n\n\n\n\n\n\nNotes\n\n\n\nNote 1: Install the packages in the order listed below.\nNote 2: All the package names listed below are case sensitive!\nNote 3: If you have a Mac with an M1 chip, download and install this tool before intalling your packages: https://mac.r-project.org/tools/gfortran-12.2-universal.pkg\nNote 4: At any point (especially if you’ve used R/Bioconductor in the past), in the console R may ask you if you want to update any old packages by asking Update all/some/none? [a/s/n]:. If you see this, type “a” at the prompt and hit Enter to update any old packages. Updating packages can sometimes take quite a bit of time to run, so please account for that before you start with these installations.\nNote 5: If you see a message in your console along the lines of “binary version available but the source version is later”, followed by a question, “Do you want to install from sources the package which needs compilation? y/n”, type n for no, and hit enter.\n\n\n(1) Install the X packages listed below from Bioconductor using the the BiocManager::install() function.\n\npackage_1\npackage_2\npackage_3\npackage_4\n\nPlease install them one-by-one as follows:\n\nBiocManager::install(\"package_1\")\nBiocManager::install(\"package_2\")\nBiocManager::install(\"package_3\")\nBiocManager::install(\"package_4\")\n\n(2) Install the Y packages listed below from CRAN using the install.packages() function.\n\npackage_5\npackage_6\npackage_7\npackage_8\npackage_9\npackage_10\npackage_11\n\nPlease install them one-by-one as follows:\n\ninstall.packages(\"package_5\")\ninstall.packages(\"package_6\")\ninstall.packages(\"package_7\")\ninstall.packages(\"package_8\")\ninstall.packages(\"package_9\")\ninstall.packages(\"package_10\")\ninstall.packages(\"package_11\")\n\n(3) Finally, please check that all the packages were installed successfully by loading them one at a time using the library() function.\n\nlibrary(package_1)\nlibrary(package_2)\nlibrary(package_3)\nlibrary(package_4)\nlibrary(package_5)\nlibrary(package_6)\nlibrary(package_7)\nlibrary(package_8)\nlibrary(package_9)\nlibrary(package_10)\nlibrary(package_11)\n\n(4) Once all packages have been loaded, run sessionInfo().\n\nsessionInfo()\n\n\n\n\n\nCitation\nTo cite material from this course in your publications, please use:\n\n\n\n\n\n\nCitation\n\n\n\nCreate Zenodo citation\n\n\nA lot of time and effort went into the preparation of these materials. Citations help us understand the needs of the community, gain recognition for our work, and attract further funding to support our teaching activities. Thank you for citing this material if it helped you in your data analysis."
  },
  {
    "objectID": "schedule/links-to-lessons.html",
    "href": "schedule/links-to-lessons.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "schedule/links-to-lessons.html#learning-objectives",
    "href": "schedule/links-to-lessons.html#learning-objectives",
    "title": "",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nLO 1\nLO 2\nLO 3\nLO 4"
  },
  {
    "objectID": "schedule/links-to-lessons.html#installations",
    "href": "schedule/links-to-lessons.html#installations",
    "title": "",
    "section": "Installations",
    "text": "Installations\n\nFollow the instructions linked here to download R and RStudio + Install Packages from CRAN and Bioconductor\nDownload this projectCREATE DROPBOX LINK STILL"
  },
  {
    "objectID": "schedule/links-to-lessons.html#lessons",
    "href": "schedule/links-to-lessons.html#lessons",
    "title": "",
    "section": "Lessons",
    "text": "Lessons\n\nIntroduction to Spatial Single Cell RNA-sequencing\nPre-processing of Spatial Data\nQuality Control\nTheory of PCA\nNormalization and regressing out unwanted variation\nClustering\nClustering quality control\nMarker Identification\nIntegration\nSpatially Derived Value\nDeconvolution\nDifferential expression\nCell-Cell Comunication\n\nSeurat Cheatsheet"
  },
  {
    "objectID": "schedule/links-to-lessons.html#building-on-this-workshop",
    "href": "schedule/links-to-lessons.html#building-on-this-workshop",
    "title": "",
    "section": "Building on this workshop",
    "text": "Building on this workshop\n\nOther online scRNA-seq courses:\n\nhttp://bioconductor.org/books/release/OSCA/\nhttps://liulab-dfci.github.io/bioinfo-combio/\nhttps://hemberg-lab.github.io/scRNA.seq.course/\nhttps://github.com/SingleCellTranscriptomics\nhttps://broadinstitute.github.io/2020_scWorkshop/\n\nResources for scRNA-seq Sample Prep:\n\nhttps://www.protocols.io/\nhttps://support.10xgenomics.com/single-cell-gene-expression/sample-prep\nhttps://community.10xgenomics.com/"
  },
  {
    "objectID": "schedule/links-to-lessons.html#resources",
    "href": "schedule/links-to-lessons.html#resources",
    "title": "",
    "section": "Resources",
    "text": "Resources\nWe have covered the analysis steps in quite a bit of detail for scRNA-seq exploration of cellular heterogeneity using the Seurat package. For more information on topics covered, we encourage you to take a look at the following resources:\n\nSeurat vignettes\nSeurat cheatsheet\nSatija Lab: Single Cell Genomics Day\n“Principal Component Analysis (PCA) clearly explained”, a video from Josh Starmer\nAdditional information about cell cycle scoring\nUsing R on the O2 cluster\nHighlighted papers for sample processing steps (pre-sequencing):\n\n“Sampling time-dependent artifacts in single-cell genomics studies.” Massoni-Badosa et al. 2019\n“Dissociation of solid tumor tissues with cold active protease for single-cell RNA-seq minimizes conserved collagenase-associated stress responses.” O’Flanagan et al. 2020\n“Systematic assessment of tissue dissociation and storage biases in single-cell and single-nucleus RNA-seq workflows.” Denisenko et al. 2020\n\nBest practices for single-cell analysis across modalities"
  },
  {
    "objectID": "lessons/Pre-reading_01.html",
    "href": "lessons/Pre-reading_01.html",
    "title": "Spatial Technologies",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#sub-topic-1",
    "href": "lessons/Pre-reading_01.html#sub-topic-1",
    "title": "Spatial Technologies",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#sub-topic-2",
    "href": "lessons/Pre-reading_01.html#sub-topic-2",
    "title": "Spatial Technologies",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#sub-topic-3",
    "href": "lessons/Pre-reading_01.html#sub-topic-3",
    "title": "Spatial Technologies",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#sub-topic-1-1",
    "href": "lessons/Pre-reading_01.html#sub-topic-1-1",
    "title": "Spatial Technologies",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#sub-topic-2-1",
    "href": "lessons/Pre-reading_01.html#sub-topic-2-1",
    "title": "Spatial Technologies",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#sub-topic-3-1",
    "href": "lessons/Pre-reading_01.html#sub-topic-3-1",
    "title": "Spatial Technologies",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#sub-topic-1-2",
    "href": "lessons/Pre-reading_01.html#sub-topic-1-2",
    "title": "Spatial Technologies",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#sub-topic-2-2",
    "href": "lessons/Pre-reading_01.html#sub-topic-2-2",
    "title": "Spatial Technologies",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#sub-topic-3-2",
    "href": "lessons/Pre-reading_01.html#sub-topic-3-2",
    "title": "Spatial Technologies",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html",
    "href": "lessons/Pre-reading_02.html",
    "title": "Pre-reading 2",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html#sub-topic-1",
    "href": "lessons/Pre-reading_02.html#sub-topic-1",
    "title": "Pre-reading 2",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html#sub-topic-2",
    "href": "lessons/Pre-reading_02.html#sub-topic-2",
    "title": "Pre-reading 2",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html#sub-topic-3",
    "href": "lessons/Pre-reading_02.html#sub-topic-3",
    "title": "Pre-reading 2",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html#sub-topic-1-1",
    "href": "lessons/Pre-reading_02.html#sub-topic-1-1",
    "title": "Pre-reading 2",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html#sub-topic-2-1",
    "href": "lessons/Pre-reading_02.html#sub-topic-2-1",
    "title": "Pre-reading 2",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html#sub-topic-3-1",
    "href": "lessons/Pre-reading_02.html#sub-topic-3-1",
    "title": "Pre-reading 2",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html#sub-topic-1-2",
    "href": "lessons/Pre-reading_02.html#sub-topic-1-2",
    "title": "Pre-reading 2",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html#sub-topic-2-2",
    "href": "lessons/Pre-reading_02.html#sub-topic-2-2",
    "title": "Pre-reading 2",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_02.html#sub-topic-3-2",
    "href": "lessons/Pre-reading_02.html#sub-topic-3-2",
    "title": "Pre-reading 2",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 2"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html",
    "href": "lessons/Pre-reading_03.html",
    "title": "Pre-reading 3",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html#sub-topic-1",
    "href": "lessons/Pre-reading_03.html#sub-topic-1",
    "title": "Pre-reading 3",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html#sub-topic-2",
    "href": "lessons/Pre-reading_03.html#sub-topic-2",
    "title": "Pre-reading 3",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html#sub-topic-3",
    "href": "lessons/Pre-reading_03.html#sub-topic-3",
    "title": "Pre-reading 3",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html#sub-topic-1-1",
    "href": "lessons/Pre-reading_03.html#sub-topic-1-1",
    "title": "Pre-reading 3",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html#sub-topic-2-1",
    "href": "lessons/Pre-reading_03.html#sub-topic-2-1",
    "title": "Pre-reading 3",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html#sub-topic-3-1",
    "href": "lessons/Pre-reading_03.html#sub-topic-3-1",
    "title": "Pre-reading 3",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html#sub-topic-1-2",
    "href": "lessons/Pre-reading_03.html#sub-topic-1-2",
    "title": "Pre-reading 3",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html#sub-topic-2-2",
    "href": "lessons/Pre-reading_03.html#sub-topic-2-2",
    "title": "Pre-reading 3",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_03.html#sub-topic-3-2",
    "href": "lessons/Pre-reading_03.html#sub-topic-3-2",
    "title": "Pre-reading 3",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3",
    "crumbs": [
      "Pre-reading:",
      "Pre-reading 3"
    ]
  },
  {
    "objectID": "lessons/09_integration.html",
    "href": "lessons/09_integration.html",
    "title": "Integration",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/09_integration.html#sub-topic-1",
    "href": "lessons/09_integration.html#sub-topic-1",
    "title": "Integration",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/09_integration.html#sub-topic-2",
    "href": "lessons/09_integration.html#sub-topic-2",
    "title": "Integration",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/09_integration.html#sub-topic-3",
    "href": "lessons/09_integration.html#sub-topic-3",
    "title": "Integration",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/09_integration.html#sub-topic-1-1",
    "href": "lessons/09_integration.html#sub-topic-1-1",
    "title": "Integration",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/09_integration.html#sub-topic-2-1",
    "href": "lessons/09_integration.html#sub-topic-2-1",
    "title": "Integration",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/09_integration.html#sub-topic-3-1",
    "href": "lessons/09_integration.html#sub-topic-3-1",
    "title": "Integration",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/09_integration.html#sub-topic-1-2",
    "href": "lessons/09_integration.html#sub-topic-1-2",
    "title": "Integration",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/09_integration.html#sub-topic-2-2",
    "href": "lessons/09_integration.html#sub-topic-2-2",
    "title": "Integration",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/09_integration.html#sub-topic-3-2",
    "href": "lessons/09_integration.html#sub-topic-3-2",
    "title": "Integration",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 2 Self-learning",
      "Integration"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA_Answer-key.html",
    "href": "lessons/04_theory_of_PCA_Answer-key.html",
    "title": "Theory of PCA Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/06_clustering_Answer-key.html",
    "href": "lessons/06_clustering_Answer-key.html",
    "title": "Clustering Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/12_dge.html",
    "href": "lessons/12_dge.html",
    "title": "Differential Gene Expression",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/12_dge.html#sub-topic-1",
    "href": "lessons/12_dge.html#sub-topic-1",
    "title": "Differential Gene Expression",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/12_dge.html#sub-topic-2",
    "href": "lessons/12_dge.html#sub-topic-2",
    "title": "Differential Gene Expression",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/12_dge.html#sub-topic-3",
    "href": "lessons/12_dge.html#sub-topic-3",
    "title": "Differential Gene Expression",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/12_dge.html#sub-topic-1-1",
    "href": "lessons/12_dge.html#sub-topic-1-1",
    "title": "Differential Gene Expression",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/12_dge.html#sub-topic-2-1",
    "href": "lessons/12_dge.html#sub-topic-2-1",
    "title": "Differential Gene Expression",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/12_dge.html#sub-topic-3-1",
    "href": "lessons/12_dge.html#sub-topic-3-1",
    "title": "Differential Gene Expression",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/12_dge.html#sub-topic-1-2",
    "href": "lessons/12_dge.html#sub-topic-1-2",
    "title": "Differential Gene Expression",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/12_dge.html#sub-topic-2-2",
    "href": "lessons/12_dge.html#sub-topic-2-2",
    "title": "Differential Gene Expression",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/12_dge.html#sub-topic-3-2",
    "href": "lessons/12_dge.html#sub-topic-3-2",
    "title": "Differential Gene Expression",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 3 Self-learning",
      "Differential Gene Expression"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication_Answer-key.html",
    "href": "lessons/13_cell-cell-communication_Answer-key.html",
    "title": "Cell-Cell Comunication Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/12_dge_Answer-key.html",
    "href": "lessons/12_dge_Answer-key.html",
    "title": "Differential Gene Expression Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/08_marker-identification.html",
    "href": "lessons/08_marker-identification.html",
    "title": "Marker Identification",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification.html#sub-topic-1",
    "href": "lessons/08_marker-identification.html#sub-topic-1",
    "title": "Marker Identification",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification.html#sub-topic-2",
    "href": "lessons/08_marker-identification.html#sub-topic-2",
    "title": "Marker Identification",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification.html#sub-topic-3",
    "href": "lessons/08_marker-identification.html#sub-topic-3",
    "title": "Marker Identification",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification.html#sub-topic-1-1",
    "href": "lessons/08_marker-identification.html#sub-topic-1-1",
    "title": "Marker Identification",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification.html#sub-topic-2-1",
    "href": "lessons/08_marker-identification.html#sub-topic-2-1",
    "title": "Marker Identification",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification.html#sub-topic-3-1",
    "href": "lessons/08_marker-identification.html#sub-topic-3-1",
    "title": "Marker Identification",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification.html#sub-topic-1-2",
    "href": "lessons/08_marker-identification.html#sub-topic-1-2",
    "title": "Marker Identification",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification.html#sub-topic-2-2",
    "href": "lessons/08_marker-identification.html#sub-topic-2-2",
    "title": "Marker Identification",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification.html#sub-topic-3-2",
    "href": "lessons/08_marker-identification.html#sub-topic-3-2",
    "title": "Marker Identification",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 2 Self-learning",
      "Marker Identification"
    ]
  },
  {
    "objectID": "lessons/08_marker-identification_Answer-key.html",
    "href": "lessons/08_marker-identification_Answer-key.html",
    "title": "Integration Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/11_deconvolution.html",
    "href": "lessons/11_deconvolution.html",
    "title": "Deconvolution",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution.html#sub-topic-1",
    "href": "lessons/11_deconvolution.html#sub-topic-1",
    "title": "Deconvolution",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution.html#sub-topic-2",
    "href": "lessons/11_deconvolution.html#sub-topic-2",
    "title": "Deconvolution",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution.html#sub-topic-3",
    "href": "lessons/11_deconvolution.html#sub-topic-3",
    "title": "Deconvolution",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution.html#sub-topic-1-1",
    "href": "lessons/11_deconvolution.html#sub-topic-1-1",
    "title": "Deconvolution",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution.html#sub-topic-2-1",
    "href": "lessons/11_deconvolution.html#sub-topic-2-1",
    "title": "Deconvolution",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution.html#sub-topic-3-1",
    "href": "lessons/11_deconvolution.html#sub-topic-3-1",
    "title": "Deconvolution",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution.html#sub-topic-1-2",
    "href": "lessons/11_deconvolution.html#sub-topic-1-2",
    "title": "Deconvolution",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution.html#sub-topic-2-2",
    "href": "lessons/11_deconvolution.html#sub-topic-2-2",
    "title": "Deconvolution",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution.html#sub-topic-3-2",
    "href": "lessons/11_deconvolution.html#sub-topic-3-2",
    "title": "Deconvolution",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 3:",
      "Deconvolution"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html",
    "href": "lessons/13_cell-cell-communication.html",
    "title": "Cell-Cell Comunication",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html#sub-topic-1",
    "href": "lessons/13_cell-cell-communication.html#sub-topic-1",
    "title": "Cell-Cell Comunication",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html#sub-topic-2",
    "href": "lessons/13_cell-cell-communication.html#sub-topic-2",
    "title": "Cell-Cell Comunication",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html#sub-topic-3",
    "href": "lessons/13_cell-cell-communication.html#sub-topic-3",
    "title": "Cell-Cell Comunication",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html#sub-topic-1-1",
    "href": "lessons/13_cell-cell-communication.html#sub-topic-1-1",
    "title": "Cell-Cell Comunication",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html#sub-topic-2-1",
    "href": "lessons/13_cell-cell-communication.html#sub-topic-2-1",
    "title": "Cell-Cell Comunication",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html#sub-topic-3-1",
    "href": "lessons/13_cell-cell-communication.html#sub-topic-3-1",
    "title": "Cell-Cell Comunication",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html#sub-topic-1-2",
    "href": "lessons/13_cell-cell-communication.html#sub-topic-1-2",
    "title": "Cell-Cell Comunication",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html#sub-topic-2-2",
    "href": "lessons/13_cell-cell-communication.html#sub-topic-2-2",
    "title": "Cell-Cell Comunication",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/13_cell-cell-communication.html#sub-topic-3-2",
    "href": "lessons/13_cell-cell-communication.html#sub-topic-3-2",
    "title": "Cell-Cell Comunication",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 4:",
      "Cell-Cell Comunication"
    ]
  },
  {
    "objectID": "lessons/11_deconvolution_Answer-key.html",
    "href": "lessons/11_deconvolution_Answer-key.html",
    "title": "Deconvolution Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html",
    "href": "lessons/07_clustering-quality-control.html",
    "title": "Clustering Quality Control",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html#sub-topic-1",
    "href": "lessons/07_clustering-quality-control.html#sub-topic-1",
    "title": "Clustering Quality Control",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html#sub-topic-2",
    "href": "lessons/07_clustering-quality-control.html#sub-topic-2",
    "title": "Clustering Quality Control",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html#sub-topic-3",
    "href": "lessons/07_clustering-quality-control.html#sub-topic-3",
    "title": "Clustering Quality Control",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html#sub-topic-1-1",
    "href": "lessons/07_clustering-quality-control.html#sub-topic-1-1",
    "title": "Clustering Quality Control",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html#sub-topic-2-1",
    "href": "lessons/07_clustering-quality-control.html#sub-topic-2-1",
    "title": "Clustering Quality Control",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html#sub-topic-3-1",
    "href": "lessons/07_clustering-quality-control.html#sub-topic-3-1",
    "title": "Clustering Quality Control",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html#sub-topic-1-2",
    "href": "lessons/07_clustering-quality-control.html#sub-topic-1-2",
    "title": "Clustering Quality Control",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html#sub-topic-2-2",
    "href": "lessons/07_clustering-quality-control.html#sub-topic-2-2",
    "title": "Clustering Quality Control",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control.html#sub-topic-3-2",
    "href": "lessons/07_clustering-quality-control.html#sub-topic-3-2",
    "title": "Clustering Quality Control",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 2 Self-learning",
      "Clustering Quality Control"
    ]
  },
  {
    "objectID": "lessons/09_integration_Answer-key.html",
    "href": "lessons/09_integration_Answer-key.html",
    "title": "Marker Identification Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html",
    "href": "lessons/02_preprocessing-of-data.html",
    "title": "Pre-processing of Spatial Data",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#sub-topic-1",
    "href": "lessons/02_preprocessing-of-data.html#sub-topic-1",
    "title": "Pre-processing of Spatial Data",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#sub-topic-2",
    "href": "lessons/02_preprocessing-of-data.html#sub-topic-2",
    "title": "Pre-processing of Spatial Data",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#sub-topic-3",
    "href": "lessons/02_preprocessing-of-data.html#sub-topic-3",
    "title": "Pre-processing of Spatial Data",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#sub-topic-1-1",
    "href": "lessons/02_preprocessing-of-data.html#sub-topic-1-1",
    "title": "Pre-processing of Spatial Data",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#sub-topic-2-1",
    "href": "lessons/02_preprocessing-of-data.html#sub-topic-2-1",
    "title": "Pre-processing of Spatial Data",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#sub-topic-3-1",
    "href": "lessons/02_preprocessing-of-data.html#sub-topic-3-1",
    "title": "Pre-processing of Spatial Data",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#sub-topic-1-2",
    "href": "lessons/02_preprocessing-of-data.html#sub-topic-1-2",
    "title": "Pre-processing of Spatial Data",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#sub-topic-2-2",
    "href": "lessons/02_preprocessing-of-data.html#sub-topic-2-2",
    "title": "Pre-processing of Spatial Data",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#sub-topic-3-2",
    "href": "lessons/02_preprocessing-of-data.html#sub-topic-3-2",
    "title": "Pre-processing of Spatial Data",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html",
    "href": "lessons/10_spatially-derived-values.html",
    "title": "Spatially Derived Values",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html#sub-topic-1",
    "href": "lessons/10_spatially-derived-values.html#sub-topic-1",
    "title": "Spatially Derived Values",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html#sub-topic-2",
    "href": "lessons/10_spatially-derived-values.html#sub-topic-2",
    "title": "Spatially Derived Values",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html#sub-topic-3",
    "href": "lessons/10_spatially-derived-values.html#sub-topic-3",
    "title": "Spatially Derived Values",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html#sub-topic-1-1",
    "href": "lessons/10_spatially-derived-values.html#sub-topic-1-1",
    "title": "Spatially Derived Values",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html#sub-topic-2-1",
    "href": "lessons/10_spatially-derived-values.html#sub-topic-2-1",
    "title": "Spatially Derived Values",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html#sub-topic-3-1",
    "href": "lessons/10_spatially-derived-values.html#sub-topic-3-1",
    "title": "Spatially Derived Values",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html#sub-topic-1-2",
    "href": "lessons/10_spatially-derived-values.html#sub-topic-1-2",
    "title": "Spatially Derived Values",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html#sub-topic-2-2",
    "href": "lessons/10_spatially-derived-values.html#sub-topic-2-2",
    "title": "Spatially Derived Values",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values.html#sub-topic-3-2",
    "href": "lessons/10_spatially-derived-values.html#sub-topic-3-2",
    "title": "Spatially Derived Values",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 3:",
      "Spatially Derived Values"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data_Answer-key.html",
    "href": "lessons/02_preprocessing-of-data_Answer-key.html",
    "title": "Pre-processing of Spatial Data Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/05_normalization_Answer-key.html",
    "href": "lessons/05_normalization_Answer-key.html",
    "title": "Normalization and Regressing Out Unwanted Variation Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/03_quality-control_Answer-key.html",
    "href": "lessons/03_quality-control_Answer-key.html",
    "title": "Quality Control Answer Key",
    "section": "",
    "text": "Exercise 1\n1. Do you notice a pattern in cells in regards to the number of UMIs and feature? Make a geom_point plots to compare these values on a per-cell basis and color each point by the mitochondrial ratio following the structure provided here\nConsidering any of these QC metrics in isolation can lead to misinterpretation of cellular signals. For example, cells with a comparatively high fraction of mitochondrial counts may be involved in respiratory processes and may be cells that you would like to keep. Likewise, other metrics can have other biological interpretations. A general rule of thumb when performing QC is to set thresholds for individual metrics to be as permissive as possible, and always consider the joint effects of these metrics.\n\nseurat_merged@meta.data %&gt;%\n  arrange(mitoRatio) %&gt;%\n  ggplot() +\n  geom_point(aes(x = nCount_Spatial.008um, \n                 y = nFeature_Spatial.008um,\n                 color = mitoRatio),\n             size = 0.5) +\n  ylim(0, 3500) + xlim(0, 3500) +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 1: Joint effect of nUMIs, nGenes, and mitoRatio\n\n\n\n\n\nGood cells will generally exhibit both higher number of genes per cell and higher numbers of UMIs (upper right quadrant of the plot). Cells that are poor quality are likely to have low genes and UMIs per cell (bottom left quadrant of the plot). With this plot we also evaluate the slope of the line, and any scatter of data points in the bottom right hand quadrant of the plot. These cells have a high number of UMIs but only a few number of genes. These could be dying cells, but also could represent a population of a low complexity celltype.\nMitochondrial read fractions are only high in particularly low count cells with few detected genes. This could be indicative of damaged/dying cells whose cytoplasmic mRNA has leaked out through a broken membrane, and thus, only mRNA located in the mitochondria is still conserved.\n\n\nExercise 2\n2. How many bins do we have per sample after this filtration step?\n\nggplot(seurat_filtered@meta.data) +\n  geom_bar(aes(x = orig.ident, fill = orig.ident),\n           color = \"black\") +\n  geom_text(aes(x = orig.ident, label=after_stat(count)), \n            stat='count', vjust=-1) +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 2: Number of cells per sample after filtration"
  },
  {
    "objectID": "lessons/06_clustering.html",
    "href": "lessons/06_clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/06_clustering.html#sub-topic-1",
    "href": "lessons/06_clustering.html#sub-topic-1",
    "title": "Clustering",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/06_clustering.html#sub-topic-2",
    "href": "lessons/06_clustering.html#sub-topic-2",
    "title": "Clustering",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/06_clustering.html#sub-topic-3",
    "href": "lessons/06_clustering.html#sub-topic-3",
    "title": "Clustering",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/06_clustering.html#sub-topic-1-1",
    "href": "lessons/06_clustering.html#sub-topic-1-1",
    "title": "Clustering",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/06_clustering.html#sub-topic-2-1",
    "href": "lessons/06_clustering.html#sub-topic-2-1",
    "title": "Clustering",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/06_clustering.html#sub-topic-3-1",
    "href": "lessons/06_clustering.html#sub-topic-3-1",
    "title": "Clustering",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/06_clustering.html#sub-topic-1-2",
    "href": "lessons/06_clustering.html#sub-topic-1-2",
    "title": "Clustering",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/06_clustering.html#sub-topic-2-2",
    "href": "lessons/06_clustering.html#sub-topic-2-2",
    "title": "Clustering",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/06_clustering.html#sub-topic-3-2",
    "href": "lessons/06_clustering.html#sub-topic-3-2",
    "title": "Clustering",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 2:",
      "Clustering"
    ]
  },
  {
    "objectID": "lessons/10_spatially-derived-values_Answer-key.html",
    "href": "lessons/10_spatially-derived-values_Answer-key.html",
    "title": "Spatially Derived Values Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/05_normalization.html",
    "href": "lessons/05_normalization.html",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/05_normalization.html#sub-topic-1",
    "href": "lessons/05_normalization.html#sub-topic-1",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/05_normalization.html#sub-topic-2",
    "href": "lessons/05_normalization.html#sub-topic-2",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/05_normalization.html#sub-topic-3",
    "href": "lessons/05_normalization.html#sub-topic-3",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/05_normalization.html#sub-topic-1-1",
    "href": "lessons/05_normalization.html#sub-topic-1-1",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/05_normalization.html#sub-topic-2-1",
    "href": "lessons/05_normalization.html#sub-topic-2-1",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/05_normalization.html#sub-topic-3-1",
    "href": "lessons/05_normalization.html#sub-topic-3-1",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/05_normalization.html#sub-topic-1-2",
    "href": "lessons/05_normalization.html#sub-topic-1-2",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/05_normalization.html#sub-topic-2-2",
    "href": "lessons/05_normalization.html#sub-topic-2-2",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/05_normalization.html#sub-topic-3-2",
    "href": "lessons/05_normalization.html#sub-topic-3-2",
    "title": "Normalization and Regressing Out Unwanted Variation",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 2:",
      "Normalization and Regressing Out Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html",
    "href": "lessons/04_theory_of_PCA.html",
    "title": "Theory of PCA",
    "section": "",
    "text": "Approximate time: 45 minutes",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#sub-topic-1",
    "href": "lessons/04_theory_of_PCA.html#sub-topic-1",
    "title": "Theory of PCA",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#sub-topic-2",
    "href": "lessons/04_theory_of_PCA.html#sub-topic-2",
    "title": "Theory of PCA",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#sub-topic-3",
    "href": "lessons/04_theory_of_PCA.html#sub-topic-3",
    "title": "Theory of PCA",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#sub-topic-1-1",
    "href": "lessons/04_theory_of_PCA.html#sub-topic-1-1",
    "title": "Theory of PCA",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#sub-topic-2-1",
    "href": "lessons/04_theory_of_PCA.html#sub-topic-2-1",
    "title": "Theory of PCA",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#sub-topic-3-1",
    "href": "lessons/04_theory_of_PCA.html#sub-topic-3-1",
    "title": "Theory of PCA",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#sub-topic-1-2",
    "href": "lessons/04_theory_of_PCA.html#sub-topic-1-2",
    "title": "Theory of PCA",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#sub-topic-2-2",
    "href": "lessons/04_theory_of_PCA.html#sub-topic-2-2",
    "title": "Theory of PCA",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#sub-topic-3-2",
    "href": "lessons/04_theory_of_PCA.html#sub-topic-3-2",
    "title": "Theory of PCA",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html",
    "href": "lessons/03_quality-control.html",
    "title": "Quality Control",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#sub-topic-1",
    "href": "lessons/03_quality-control.html#sub-topic-1",
    "title": "Quality Control",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#sub-topic-2",
    "href": "lessons/03_quality-control.html#sub-topic-2",
    "title": "Quality Control",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#sub-topic-3",
    "href": "lessons/03_quality-control.html#sub-topic-3",
    "title": "Quality Control",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#sub-topic-1-1",
    "href": "lessons/03_quality-control.html#sub-topic-1-1",
    "title": "Quality Control",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#sub-topic-2-1",
    "href": "lessons/03_quality-control.html#sub-topic-2-1",
    "title": "Quality Control",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#sub-topic-3-1",
    "href": "lessons/03_quality-control.html#sub-topic-3-1",
    "title": "Quality Control",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#sub-topic-1-2",
    "href": "lessons/03_quality-control.html#sub-topic-1-2",
    "title": "Quality Control",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#sub-topic-2-2",
    "href": "lessons/03_quality-control.html#sub-topic-2-2",
    "title": "Quality Control",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#sub-topic-3-2",
    "href": "lessons/03_quality-control.html#sub-topic-3-2",
    "title": "Quality Control",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/07_clustering-quality-control_Answer-key.html",
    "href": "lessons/07_clustering-quality-control_Answer-key.html",
    "title": "Clustering Quality Control Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "schedule/schedule.html",
    "href": "schedule/schedule.html",
    "title": "Introduction to Spatial Single-cell RNA-seq Schedule",
    "section": "",
    "text": "Spatial Technology Overview\nPre-reading 2\nPre-reading 3"
  },
  {
    "objectID": "schedule/schedule.html#pre-reading",
    "href": "schedule/schedule.html#pre-reading",
    "title": "Introduction to Spatial Single-cell RNA-seq Schedule",
    "section": "",
    "text": "Spatial Technology Overview\nPre-reading 2\nPre-reading 3"
  },
  {
    "objectID": "schedule/schedule.html#day-1",
    "href": "schedule/schedule.html#day-1",
    "title": "Introduction to Spatial Single-cell RNA-seq Schedule",
    "section": "Day 1",
    "text": "Day 1\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n09:30 - 09:45\nWorkshop introduction\nWill\n\n\n09:45 - 10:45\nIntroduction to Spatial Single Cell RNA-sequencing\nDr. Mandovi Chatterjee\n\n\n10:45 - 10:50\nBreak\n\n\n\n10:50 - 11:15\nscRNA-seq pre-reading discussion\nAll\n\n\n11:00 - 11:45\nLoading Spatial Data\nNoor\n\n\n11:45 - 12:00\nOverview of self-learning materials and homework submission\nWill\n\n\n\n\nBefore the next class:\nI. Please study the contents and work through all the code within the following lessons:\n\nQuality Control\n\n\nClick here for a preview of this lesson\n\nBrief description of the lessonIn this lesson you will: - LO 1 - LO 2 - LO 3\n\nTheory of PCA\n\n\nClick here for a preview of this lesson\n\nBefore we can begin the next steps of the workflow, we need to make sure you have a good understanding of Principal Components Analysis (PCA). This method will be utilized in the scRNA-seq analysis workflow, and this foundation will help you better navigate those steps and interpretation of results.\n\n\n\nSubmit your work:\n\n\nEach lesson above contains exercises; please go through each of them.\nSubmit your answers to the exercises using this Google form(NEED LINK STILL) on the day before the next class.\n\n\n\nQuestions?\n\nIf you get stuck due to an error while running code in the lesson, email us"
  },
  {
    "objectID": "schedule/schedule.html#day-2",
    "href": "schedule/schedule.html#day-2",
    "title": "Introduction to Spatial Single-cell RNA-seq Schedule",
    "section": "Day 2",
    "text": "Day 2\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n09:30 - 10:00\nSelf-learning lessons discussion\nAll\n\n\n10:00 - 11:00\nNormalization and Sketch Downsampling\nNoor\n\n\n11:00 - 11:05\nBreak\n\n\n\n11:05 - 12:00\nscRNA-seq Workflow\nWill\n\n\n\n\nBefore the next class:\nI. Please study the contents and work through all the code within the following lessons:\n\nIntegration\nSpatially Derived Clusters\n\n\nClick here for a preview of this lesson\n\nBrief description of the lessonIn this lesson you will: - LO 1 - LO 2 - LO 3"
  },
  {
    "objectID": "schedule/schedule.html#day-3",
    "href": "schedule/schedule.html#day-3",
    "title": "Introduction to Spatial Single-cell RNA-seq Schedule",
    "section": "Day 3",
    "text": "Day 3\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n9:30 - 10:15\nSelf-learning lessons discussion\nAll\n\n\n10:15 - 11:00\nSpatially Derived Values\nNoor\n\n\n11:00 - 11:05\nBreak\n\n\n\n11:05 - 12:00\nDeconvolution\nWill\n\n\n\n\nBefore the next class:\nI. Please study the contents and work through all the code within the following lessons:\n\nDifferential Gene Expression\n\n\nClick here for a preview of this lesson\n\nBrief description of the lessonIn this lesson you will: - LO 1 - LO 2 - LO 3\n\nSeurat Cheatsheet\n\n\nClick here for a preview of this lesson\n\nAt this point, we have populated our seurat object with many different pieces of information. Knowing how to access different values will allow you to interact more efficiently with your dataset. In this lesson you will: - Explore the different parts of a seurat object. - Use the built-in functions from the Seurat package for visualizations and grabbing data."
  },
  {
    "objectID": "schedule/schedule.html#day-4",
    "href": "schedule/schedule.html#day-4",
    "title": "Introduction to Spatial Single-cell RNA-seq Schedule",
    "section": "Day 4",
    "text": "Day 4\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n9:30 - 10:15\nSelf-learning lessons discussion\nAll\n\n\n10:15 - 11:15\nCell-Cell Comunication\nNoor\n\n\n11:15 - 11:20\nBreak\n\n\n\n11:20 - 11:45\nOverview and Final Q & A\nAll\n\n\n11:45- 12:00\nWrap up\nWill"
  },
  {
    "objectID": "schedule/schedule.html#resources",
    "href": "schedule/schedule.html#resources",
    "title": "Introduction to Spatial Single-cell RNA-seq Schedule",
    "section": "Resources",
    "text": "Resources\nWe have covered the analysis steps in quite a bit of detail for scRNA-seq exploration of cellular heterogeneity using the Seurat package. For more information on topics covered, we encourage you to take a look at the following resources:\n\nSeurat-focused\n\nSeurat vignettes\nSeurat cheatsheet\nSatija Lab: Single Cell Genomics Day\n\n\n\nScaling up: analysis on HPC\n\nUsing RStudio on O2\n\nHMSRC wiki page\nHBC RStudio on O2 tutorial\n\n\n\n\nHighlighted papers\n\n\nOther online courses:"
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#creating-an-example-data-set",
    "href": "lessons/04_theory_of_PCA.html#creating-an-example-data-set",
    "title": "Theory of PCA",
    "section": "Creating an example data set",
    "text": "Creating an example data set\nWe are going to discuss the steps for deriving a Principal Components analysis, but in order to do it, we are going to use an example dataset. Let’s start by creating an tibble that has gene expression values for two genes from four cells.\n\n# Create a vector for Cell IDs\ncells &lt;- c(\"Cell_1\", \"Cell_2\", \"Cell_3\", \"Cell_4\")\n# Create a vector to hold expression values for Gene A across all of the cells\nGene_A &lt;- c(0, 12, 65, 23)\n# Create a vector to hold expression values for Gene B across all of the cells\nGene_B &lt;- c(4, 30, 57, 18)\n\n# Create a tibble to hold the cell names and expression values\nexpression_tibble &lt;- tibble(cells, Gene_A, Gene_B)\n\n# View the expression tibble\nexpression_tibble\n\n# A tibble: 4 × 3\n  cells  Gene_A Gene_B\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Cell_1      0      4\n2 Cell_2     12     30\n3 Cell_3     65     57\n4 Cell_4     23     18\n\n\nLet’s get an idea of what our data looks like by plotting it:\n\n# Create a plot to view the raw expression data\nggplot(expression_tibble, aes(x = Gene_A, y = Gene_B, label = cells)) +\n  geom_point(color = \"cornflowerblue\") +\n  geom_text(hjust = 0, vjust = -1) +\n  xlim(0, 80) +\n  ylim(0, 80) +\n  theme_bw() +\n  xlab(\"Gene A\") +\n  ylab(\"Gene B\") +\n  ggtitle(\"Example Expression Values from Four Cells\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nNow if were were to consider our data set that has X genes and Y cells, then this plot would have X dimensions and Y points.",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#re-centering-the-dataset",
    "href": "lessons/04_theory_of_PCA.html#re-centering-the-dataset",
    "title": "Theory of PCA",
    "section": "Re-centering the dataset",
    "text": "Re-centering the dataset\nWhen performing PCA, the first step is to re-center the data so that the center of the data is the origin. In order to do this, we need to do two steps:\n1. Find the center of the data\nWe can find the center of the data by taking the average gene expression across each gene (dimension).\n\n# Determine the center of the data by:\n# Finding the average expression of gene A\nGene_A_mean &lt;- mean(expression_tibble$Gene_A)\n# Finding the average expression of gene B\nGene_B_mean &lt;- mean(expression_tibble$Gene_B)\n\n# Create a vector to hold the center of the data\ncenter_of_data &lt;- c(Gene_A_mean, Gene_B_mean)\n# Assign names to the components of the vector\nnames(center_of_data) &lt;- c(\"Gene_A\", \"Gene_B\")\n# Print out the center_of_data vector\ncenter_of_data\n\nGene_A Gene_B \n 25.00  27.25 \n\n\nThe new center of the data will be where ( 25, 27.25 ) is currently. We can visualize this center and inspect that this is does in fact appear to be roughly in the middle of the data.\n\n# View where the center of the data is located\nggplot(expression_tibble, aes(x = Gene_A, y = Gene_B, label = cells)) +\n  geom_point(color = \"cornflowerblue\") +\n    annotate(\"point\", x = Gene_A_mean, y = Gene_B_mean, color = \"red\", size = 3) +\n  geom_text(hjust = 0, vjust = -1) +\n  annotate(\"text\", x = Gene_A_mean, y = Gene_B_mean, color = \"red\", label=\"New Center\", hjust = 0, vjust = -1) +\n  xlim(0, 80) +\n  ylim(0, 80) +\n  theme_bw() +\n  xlab(\"Gene A\") +\n  ylab(\"Gene B\") +\n  ggtitle(\"Example Expression Values from Four Cells\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n2. Translate the points from their raw expression coordinates to coordinates centered around the center of the data\nNext, we need to shift the points so that the center of the data corresponds to the origin. We can do this by subtracting the mean value from each gene from the raw values.\n\n# Shift the data points so that they data is centered on the origin\nrecentered_expression_tibble &lt;- expression_tibble %&gt;%\n  mutate(\n    Gene_A = Gene_A - Gene_A_mean,\n    Gene_B = Gene_B - Gene_B_mean\n  )\n\n# Print out the re-centered data\nrecentered_expression_tibble\n\n# A tibble: 4 × 3\n  cells  Gene_A Gene_B\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Cell_1    -25 -23.2 \n2 Cell_2    -13   2.75\n3 Cell_3     40  29.8 \n4 Cell_4     -2  -9.25\n\n\nAs with any data analysis, it is always a good idea to visualize your data to ensure that it appears to behaving how you intended. So let’s visualize our re-centered data to ensure that the data appears centered around the origin.\n\n# Plot the raw data after it has been shifted to have the center of the data align with the origin\nggplot(recentered_expression_tibble, aes(x = Gene_A, y = Gene_B, label = cells)) +\n  geom_point(color = \"cornflowerblue\") +\n  annotate(\"point\", x = 0, y = 0, color = \"red\", size = 3) +\n  geom_text(hjust = 0, vjust = -1) +\n  annotate(\"text\", x = 0, y = 0, color = \"red\", label=\"New Center\", hjust = 0, vjust = -1) +\n  xlim(-50, 50) +\n  ylim(-50, 50) +\n  theme_bw() +\n  xlab(\"Gene A\") +\n  ylab(\"Gene B\") +\n  ggtitle(\"Example Re-centered Expression Values from Four Cells\") +\n  theme(plot.title = element_text(hjust = 0.5))",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#principal-component-scores",
    "href": "lessons/04_theory_of_PCA.html#principal-component-scores",
    "title": "Theory of PCA",
    "section": "Principal Component Scores",
    "text": "Principal Component Scores\nNow that we have our re-centered expression matrix and eigenvectors, we can perform matrix multiplication to obtain our principal component scores. This is where we are transforming our data from the re-centered expression into Principal Components space by the weight, or influence, of the eigenvector.\n\n\n# Transform the data into PC space by multiply the re-centered expression matrix by the eigenvectors\npc_scores &lt;- recentered_expression_matrix %*% eig$vectors\n# Name the columns in pc_scores object\ncolnames(pc_scores) &lt;- c(\"PC_1\", \"PC_2\")\n\n# Print out the pc_scores object\npc_scores\n\n             PC_1       PC_2\nCell_1  34.012581   2.950736\nCell_2   8.557355 -10.165342\nCell_3 -49.837081   1.152337\nCell_4   7.267145   6.062269",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#percent-explained",
    "href": "lessons/04_theory_of_PCA.html#percent-explained",
    "title": "Theory of PCA",
    "section": "Percent Explained",
    "text": "Percent Explained\n\npct_var_explained &lt;- (eig$values / sum(eig$values)) * 100\nnames(pct_var_explained) &lt;- c(\"PC_1\", \"PC_2\")\n\npct_var_explained\n\n    PC_1     PC_2 \n96.16723  3.83277",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#create-the-eigenvectors-and-eignvalues-from-the-covariance-matrix",
    "href": "lessons/04_theory_of_PCA.html#create-the-eigenvectors-and-eignvalues-from-the-covariance-matrix",
    "title": "Theory of PCA",
    "section": "Create the Eigenvectors and Eignvalues from the covariance matrix",
    "text": "Create the Eigenvectors and Eignvalues from the covariance matrix\nNow that we have a covariance matrix for the re-centered expression values. We need to estimate the eigenvalues and eigenvectors of the covariance matrix.\n\neig &lt;- eigen(cov_matrix)\n\neig\n\neigen() decomposition\n$values\n[1] 1255.543   50.040\n\n$vectors\n           [,1]       [,2]\n[1,] -0.7883911  0.6151743\n[2,] -0.6151743 -0.7883911\n\n\nIf we wanted to do this by hand then we can do this by setting the determinant of the covariance matrix minus \\(\\lambda\\) times the identify matrix equal to 0 and solving for \\(\\lambda\\).\n\nThis can be simplified to:\n\nWe can now replace the variance and covariance values with the values that we have from the covariance matrix and solve for \\(\\lambda\\). This results in \\(\\lambda\\)1 = 1255.543 and \\(\\lambda\\)2 = 50.04.\nWe can see that this is equal to the eigenvalues returned from our eig object:\n\neig$values\n\n[1] 1255.543   50.040\n\n\n\neig$vectors\n\n           [,1]       [,2]\n[1,] -0.7883911  0.6151743\n[2,] -0.6151743 -0.7883911",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#prcomp-comparison",
    "href": "lessons/04_theory_of_PCA.html#prcomp-comparison",
    "title": "Theory of PCA",
    "section": "prcomp() comparison",
    "text": "prcomp() comparison\nAt this point we have completed a principal components analysis, but we can also compare it to how R does a principal components analysis and see how our results compare. One way to do a principal components analysis in R is to us the prcomp() function in R.\nIn order to run prcomp(), we need to start from an expression matrix and move the cell IDs to the rownames:\n\n# Run prcomp() on the expression tibble after moving the cell IDs to be rownames\nprcomp_PCA &lt;- expression_tibble %&gt;% \n  column_to_rownames(\"cells\") %&gt;% \n  prcomp()\n\nLet’s inspect the output from prcomp() to ensure that we are getting the same output:\n\nCenter of the Data\nFirst we can ensure that we have the same center of the data. prcomp() says that the center of the data is:\n\nprcomp_PCA$center\n\nGene_A Gene_B \n 25.00  27.25 \n\n\nWe can compare this with\nPC Scores\n\nprcomp_PCA$x\n\n              PC1        PC2\nCell_1 -34.012581   2.950736\nCell_2  -8.557355 -10.165342\nCell_3  49.837081   1.152337\nCell_4  -7.267145   6.062269\n\npc_scores\n\n             PC_1       PC_2\nCell_1  34.012581   2.950736\nCell_2   8.557355 -10.165342\nCell_3 -49.837081   1.152337\nCell_4   7.267145   6.062269\n\n\n\npct_var_explained\n\n    PC_1     PC_2 \n96.16723  3.83277 \n\nprcomp_PCA$center\n\nGene_A Gene_B \n 25.00  27.25 \n\neig$vectors\n\n           [,1]       [,2]\n[1,] -0.7883911  0.6151743\n[2,] -0.6151743 -0.7883911\n\nprcomp_PCA$rotation\n\n             PC1        PC2\nGene_A 0.7883911  0.6151743\nGene_B 0.6151743 -0.7883911\n\nvar_explained_prcomp &lt;- prcomp_PCA$sdev ** 2\npct_var_explained_prcomp &lt;- (var_explained_prcomp / sum(var_explained_prcomp)) * 100\npct_var_explained_prcomp\n\n[1] 96.16723  3.83277\n\npct_var_explained\n\n    PC_1     PC_2 \n96.16723  3.83277 \n\n\nNote: It is okay if the sign for the Principal Components is flipped. Principal Components are eigenvectors of the covariance matrix and the sign of an eigenvectors is arbitrary.",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#create-a-covariance-matrix",
    "href": "lessons/04_theory_of_PCA.html#create-a-covariance-matrix",
    "title": "Theory of PCA",
    "section": "Create a covariance matrix",
    "text": "Create a covariance matrix\nThe next step that we will after we have re-centered our data around the origin is to calculate the covariance matrix. As a reminder, the covariance is the joint variability of two random variables. In this case our random variables are the genes. The illustration below we provide examples for positive and negative covariance values along with a covariance that is near zero.\n\nThe equation to estimate the sample covariance is:\n\nWhere:\n\nX is Gene A\nY is Gene B\nn is the number of cells\nxi is an expression value for Gene A\n\\(\\bar{x}\\) is the mean expression value for Gene A\nyi is an expression value for Gene B\n\\(\\bar{y}\\) is the mean expression value for Gene B\n\nNow we will calculate the covariance for all pairwise comparisons for our re-centered expression data.\n\n# Move the cell IDs to the rownames and convert the tibble to a matrix\nrecentered_expression_matrix &lt;- recentered_expression_tibble %&gt;% \n  column_to_rownames(\"cells\") %&gt;% \n  as.matrix()\n\n# Create a covariance matrix\ncov_matrix &lt;- cov(recentered_expression_matrix)\n\n# Print out the covariance matrix\ncov_matrix\n\n         Gene_A   Gene_B\nGene_A 799.3333 584.6667\nGene_B 584.6667 506.2500\n\n\nLet’s go ahead and manually check a covariance by hand to ensure that we trust the outputted covariance matrix. Let’s estimate the covariance of Gene A and Gene B.\n\n# Estimate the covariance of Gene A and Gene B by hand\n(1/(4-1))*((0-25)*(4-27.25) + (12-25)*(30-27.25) + (65-25)*(57-27.25) + (23-25)*(18-27.25))\n\n[1] 584.6667\n\n# Or you can use the covariance function\ncov(recentered_expression_matrix[, \"Gene_A\"], recentered_expression_matrix[, \"Gene_B\"])\n\n[1] 584.6667\n\n\nThis value should match the covariance found in our covariance matrix for the covariance between Gene A and Gene B.\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1\nThere are a couple properties of variance and co-variance that we can verify:\ncov(X,X) is equal to var(X). We can observe this is mathematically below:\n\nAs a result, you will sometimes see covariance matrices written as:\n\n\nConfirm this property by estimating the variance for Gene A.\n\n\n# Estimate the variance for Gene A\nvar(recentered_expression_matrix[, \"Gene_A\"])\n\n[1] 799.3333\n\n\n\nNow estimate the covariance for Gene A and Gene A\n\n\n# Estimate the covariance for Gene A and Gene A\ncov(recentered_expression_matrix[, \"Gene_A\"], recentered_expression_matrix[, \"Gene_A\"])\n\n[1] 799.3333\n\n\n\nIs the value the same? Does it match the value in the covariance matrix for Gene A and Gene A?\n\n\n# Extract the covariance estimate of Gene A and Gene A from the covariance matrix\ncov_matrix[\"Gene_A\", \"Gene_A\"]\n\n[1] 799.3333\n\n\ncov(X,Y) is equal to cov(Y,X). We can observe this is mathematically below:\n\n\nEstimate the covariance of Gene B and Gene A.\n\n\n# Estimate the covariance of Gene B and Gene A\ncov(recentered_expression_tibble[, \"Gene_B\"], recentered_expression_tibble[, \"Gene_A\"])\n\n         Gene_A\nGene_B 584.6667\n\n\n\nHow does this compare to the covariance that we estimated by hand?",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#calculate-eigenvalues-from-the-covariance-matrix",
    "href": "lessons/04_theory_of_PCA.html#calculate-eigenvalues-from-the-covariance-matrix",
    "title": "Theory of PCA",
    "section": "Calculate Eigenvalues from the covariance matrix",
    "text": "Calculate Eigenvalues from the covariance matrix\nFirst, we will need to calculate our eigenvalues, which in turn will be used to let us know how much of the variance explained is explained by each principal component.\nNow that we have a covariance matrix for the re-centered expression values. We need to estimate the eigenvalues and eigenvectors of the covariance matrix.\n\neig &lt;- eigen(cov_matrix)\n\neig\n\neigen() decomposition\n$values\n[1] 1255.543   50.040\n\n$vectors\n           [,1]       [,2]\n[1,] -0.7883911  0.6151743\n[2,] -0.6151743 -0.7883911\n\n\nIf we wanted to do this by hand then we can do this by setting the determinant of the covariance matrix minus \\(\\lambda\\) times the identify matrix equal to 0 and solving for \\(\\lambda\\).\n\nThis can be simplified to:\n\nWe can now replace the variance and covariance values with the values that we have from the covariance matrix and solve for \\(\\lambda\\). This results in two lambda values: \\(\\lambda\\)1 = 1255.543 and \\(\\lambda\\)2 = 50.04.\nWe can see that this is equal to the eigenvalues returned from our eig object:\n\neig$values\n\n[1] 1255.543   50.040",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#calculate-eigenvectors-from-the-covariance-matrix",
    "href": "lessons/04_theory_of_PCA.html#calculate-eigenvectors-from-the-covariance-matrix",
    "title": "Theory of PCA",
    "section": "Calculate Eigenvectors from the covariance matrix",
    "text": "Calculate Eigenvectors from the covariance matrix\nWe can think of the eigenvectors as the weights, or influence, for transforming our re-centered expression values into PCA space.\nIn order to find the eigenvectors, we need to substitute the values in the covariance matrix along with one of our \\(\\lambda\\) values, \\(\\lambda\\)1 to find the associated eigenvector, v1. This results in v1 being equal to -0.7883911, -0.6151743.\n\nWe can confirm this by plugging our covariance matrix, eigenvalues and eigen vectors back into the above equation and it should return 0, or near 0 (due to rounding errors).\n\n(cov_matrix - eig$values[1]*diag(2)) %*% eig$vectors[,1]\n\n                [,1]\nGene_A -5.484729e-14\nGene_B -1.507339e-14\n\n\nWe then repeat this process for \\(\\lambda\\)2 in order to to find its associated eigenvector, v2, which results in 0.6151743, -0.7883911.\n\neig$vectors\n\n           [,1]       [,2]\n[1,] -0.7883911  0.6151743\n[2,] -0.6151743 -0.7883911",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#percent-variance-explained",
    "href": "lessons/04_theory_of_PCA.html#percent-variance-explained",
    "title": "Theory of PCA",
    "section": "Percent Variance Explained",
    "text": "Percent Variance Explained\nWe are likely interested in knowing in knowing the amount of variance explained in our data by each principal component. As we alluded to earlier, we can use the eigenvalues to help us with this. The sum of all of the eigenvalues captures the total variance explained by the principal components analysis.\nThus, if we want to know the proportion of the variance explained by each principal component, then we would need to divide each eigenvalue by the total variance explained (the sum of the eigenvalues) and if we wanted this as a percentage then we would need to multiply it by 100.\n\n# Calculate the percent of variance explained by each PC using the eigenvalues\npct_var_explained &lt;- (eig$values / sum(eig$values)) * 100\n# Name the elements of the pct_var_explained by their PC\nnames(pct_var_explained) &lt;- c(\"PC_1\", \"PC_2\")\n\n# Print out the percent of variance explained by each PC\npct_var_explained\n\n    PC_1     PC_2 \n96.16723  3.83277",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#calculate-eigenvalues-and-eigenvectors-from-the-covariance-matrix",
    "href": "lessons/04_theory_of_PCA.html#calculate-eigenvalues-and-eigenvectors-from-the-covariance-matrix",
    "title": "Theory of PCA",
    "section": "Calculate Eigenvalues and Eigenvectors from the Covariance Matrix",
    "text": "Calculate Eigenvalues and Eigenvectors from the Covariance Matrix\nFirst, we will need to calculate our eigenvalues, which are a measure of variance for a principal component. We can then use eigenvalues to calculate our eigenvectors, but R will do this all in a single step for us. We can think of the eigenvectors as the weights, or influence, for transforming our re-centered expression values into PCA space.\nNow that we have a covariance matrix for the re-centered expression values, we need to estimate the eigenvalues and eigenvectors for the covariance matrix.\n\n# Find the eigenvalues and eigenvectors of the covariance matrix\neig &lt;- eigen(cov_matrix)\n\n# Print the output from eigen()\neig\n\neigen() decomposition\n$values\n[1] 1255.543   50.040\n\n$vectors\n           [,1]       [,2]\n[1,] -0.7883911  0.6151743\n[2,] -0.6151743 -0.7883911\n\n\n\n\n\n\n\n\nClick here to see how to calculate eigenvalues and eigenvectors\n\n\n\n\n\nCalculating Eigenvalues\nIf we wanted to do this by hand then we need to set the determinant of the covariance matrix minus \\(\\lambda\\) times the identify matrix equal to 0 and solving for \\(\\lambda\\).\n\nIn this case it can be simplified to:\n\nWe can now replace the variance and covariance values with the values that we have from the covariance matrix and solve for \\(\\lambda\\). This results in two lambda values: \\(\\lambda\\)1 = 1255.543 and \\(\\lambda\\)2 = 50.04.\nWe can see that this is equal to the eigenvalues returned from our eig object:\n\n# Print the eigenvalues\neig$values\n\n[1] 1255.543   50.040\n\n\nCalculating Eigenvectors\nIn order to find the eigenvectors, we need to substitute the variacne and covariance values from the covariance matrix along with one of our \\(\\lambda\\) values, \\(\\lambda\\)1 to find the associated eigenvector, v1. This results in v1 being equal to -0.7883911, -0.6151743.\n\nWe can confirm this by plugging our covariance matrix, eigenvalues and eigenvectors back into the above equation and it should return 0, or near 0 (due to rounding errors).\n\n# Check the eigenvalues and eigenvectors\n(cov_matrix - eig$values[1]*diag(2)) %*% eig$vectors[,1]\n\n                [,1]\nGene_A -5.484729e-14\nGene_B -1.507339e-14\n\n\nWe then repeat this process for \\(\\lambda\\)2 in order to to find its associated eigenvector, v2, which results in 0.6151743, -0.7883911. Thus, our resulting matrix of eigenvectors appears as:\n\n# Print the eigenvectors\neig$vectors\n\n           [,1]       [,2]\n[1,] -0.7883911  0.6151743\n[2,] -0.6151743 -0.7883911",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#plotting-our-principal-components",
    "href": "lessons/04_theory_of_PCA.html#plotting-our-principal-components",
    "title": "Theory of PCA",
    "section": "Plotting our Principal Components",
    "text": "Plotting our Principal Components\nWith out principal components in hand, we will create a visualization of the principal components.\n\n# Create a tibble to hold the PC scores we found and also make the Cell IDs into a column\npc_scores_tibble &lt;- pc_scores %&gt;% \n  as.data.frame() %&gt;% \n  rownames_to_column(\"cells\") %&gt;% \n  as_tibble()\n\n# Plot the PC scores we found\nggplot(pc_scores_tibble, aes(x = PC_1, y = PC_2, label = cells)) +\n  geom_point( color = \"cornflowerblue\") +\n  geom_text(hjust = 0, vjust = -1) +\n  theme_bw() +\n  xlim(-50, 50) +\n  ylim(-12, 12) +\n  xlab(paste0(\"PC 1 (Variance Explained \", round(pct_var_explained[\"PC_1\"], digits = 2),\"%)\")) +\n  ylab(paste0(\"PC 2 (Variance Explained \", round(pct_var_explained[\"PC_2\"], digits = 2),\"%)\")) +\n  ggtitle(\"PCA of Expression Values from Four Cells\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nWhen looking at the percent explained by each principal component, the first principal component should explain the most and each of the following principal components should explain less than the previous principal component. Let’s have a look at our pct_var_explained object, are our results congruent with the expectation this expectation?",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#center-of-the-data",
    "href": "lessons/04_theory_of_PCA.html#center-of-the-data",
    "title": "Theory of PCA",
    "section": "Center of the Data",
    "text": "Center of the Data\nFirst we can ensure that we have the same center of the data. prcomp() says that the center of the data is:\n\n# Print the center of the data found by prcomp()\nprcomp_PCA$center\n\nGene_A Gene_B \n 25.00  27.25 \n\n\nWe can compare this with what we derived as the center of the data:\n\n# Print the center of the data we found\ncenter_of_data\n\nGene_A Gene_B \n 25.00  27.25 \n\n\nThey match which is a great sign that we did this correctly!",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#eigenvalues",
    "href": "lessons/04_theory_of_PCA.html#eigenvalues",
    "title": "Theory of PCA",
    "section": "Eigenvalues",
    "text": "Eigenvalues\nNote that eigenvalues are the variance for a particular principal component and that variance is the square of the standard deviation as shown below.\n\nprcomp() reports the standard deviation, so we will need to square the items in the prcomp_PCA$sdev slot in order to recover our variance, or eigenvalues.\n\n# Print the eigenvalues found by prcomp() by squaring prcomp_PCA$sdev\nprcomp_eigenvalues &lt;- prcomp_PCA$sdev ** 2\n# Name the elements of the prcomp_eigenvalues by their PC\nnames(prcomp_eigenvalues) &lt;- c(\"PC_1\", \"PC_2\")\n\n# Print out prcomp_eigenvalues\nprcomp_eigenvalues\n\n    PC_1     PC_2 \n1255.543   50.040 \n\n\nWe can compare this with our estimation of eiganvalues by hand:\n\n# Print the eigenvalues we found\neig$values\n\n[1] 1255.543   50.040",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#eigenvectors",
    "href": "lessons/04_theory_of_PCA.html#eigenvectors",
    "title": "Theory of PCA",
    "section": "Eigenvectors",
    "text": "Eigenvectors\nLet’s go ahead and compare the eigenvectors from prcomp() to the eigenvectors that we calculated. prcomp() calculated the eigenvectors as:\n\n# Print the eigenvectors found by prcomp()\nprcomp_PCA$rotation\n\n             PC1        PC2\nGene_A 0.7883911  0.6151743\nGene_B 0.6151743 -0.7883911\n\n\nWhile we calculated the eigenvectors as:\n\n# Print the eigenvectors we found\neig$vectors\n\n           [,1]       [,2]\n[1,] -0.7883911  0.6151743\n[2,] -0.6151743 -0.7883911\n\n\nWe can see that the values are the same, but the sign is flipped between the two methods. This is because eigenvectors are only defined “up to sign”. This means for a given eigenvalue, the eigenvector v1 and -v1 are the same line, but point in different directions. This does not impact our principal components calculations. However, it could mean that a plot derived v1 will look rotated 180° when compared to a plot derived from -v1. Regardless, it looks like we have the same eigenvectors in both approaches.",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/04_theory_of_PCA.html#pc-scores",
    "href": "lessons/04_theory_of_PCA.html#pc-scores",
    "title": "Theory of PCA",
    "section": "PC Scores",
    "text": "PC Scores\nFinally, we can check our PC scores to ensure that they are also equivalent. We should note that since the eigenvector from prcomp() and the eigenvector we calculated differed by sign and eigenvectors are multiplied by the re-centered expression, then we should expect our principal components to also differ by sign. The principal components from prcomp() are:\n\n# Print the PC scores found by prcomp()\nprcomp_PCA$x\n\n              PC1        PC2\nCell_1 -34.012581   2.950736\nCell_2  -8.557355 -10.165342\nCell_3  49.837081   1.152337\nCell_4  -7.267145   6.062269\n\n\nWhile our principal components were:\n\n# Print the PC scores we found\npc_scores\n\n             PC_1       PC_2\nCell_1  34.012581   2.950736\nCell_2   8.557355 -10.165342\nCell_3 -49.837081   1.152337\nCell_4   7.267145   6.062269\n\n\nOnce again, the values are the same, but the only difference is the sign, which comes from the arbitrary direction of the eigenvector.\n\n\n\n\n\n\nExercise 3\n\n\n\nCreate a plot of the Principal Components Analysis derived from prcomp(). Is it the same as the plot we derived except only rotated 180°?\n\n# Create a tibble to hold the PC scores prcomp() found and also make the Cell IDs into a column\nprcomp_pc_scores_tibble &lt;- prcomp_PCA$x %&gt;% \n  as.data.frame() %&gt;% \n  rownames_to_column(\"cells\") %&gt;% \n  as_tibble()\n\n# Plot the PC scores found by prcomp()\nggplot(prcomp_pc_scores_tibble, aes(x = PC1, y = PC2, label = cells)) +\n  geom_point( color = \"cornflowerblue\") +\n  geom_text(hjust = 0, vjust = -1) +\n  theme_bw() +\n  xlim(-50, 50) +\n  ylim(-12, 12) +\n  xlab(paste0(\"PC 1 (Variance Explained \", round(prcomp_eigenvalues[\"PC_1\"], digits = 2),\"%)\")) +\n  ylab(paste0(\"PC 2 (Variance Explained \", round(prcomp_eigenvalues[\"PC_2\"], digits = 2),\"%)\")) +\n  ggtitle(\"PCA of Expression Values from Four Cells\") +\n  theme(plot.title = element_text(hjust = 0.5))",
    "crumbs": [
      "Day 1 Self-learning:",
      "Theory of PCA"
    ]
  },
  {
    "objectID": "lessons/Aside_eigen_math.html",
    "href": "lessons/Aside_eigen_math.html",
    "title": "Theory of PCA - Eigen Derivation",
    "section": "",
    "text": "Tossed some eigenvalue and eigenvector formulas in here. Maybe we will flesh it out later if we want to.\n\n\n\n\n\n\nThis results in \\(\\lambda\\) = {{ eig[[‘values’]][1] }} and \\(\\lambda\\) = {{ eig[[‘values’]][2] }}."
  },
  {
    "objectID": "lessons/Aside_subsetting_slide.html",
    "href": "lessons/Aside_subsetting_slide.html",
    "title": "Subsetting a Slide",
    "section": "",
    "text": "Improve exercise\nRun lesson on O2 in order to get directory tree and images following the loop then put those parts in the download.sh and embed them in the lesson\nPolish\n\nApproximate time: 45 minutes"
  },
  {
    "objectID": "lessons/Aside_subsetting_slide.html#pixel-coordinate-space",
    "href": "lessons/Aside_subsetting_slide.html#pixel-coordinate-space",
    "title": "Subsetting a Slide",
    "section": "Pixel Coordinate Space",
    "text": "Pixel Coordinate Space\nWithin this Seurat object, we also have coordinate information stored that we will need to use to subset our slide. In order to extract this coordinate information from the Seurat object, we will use the GetTissueCoordinates() function:\n\n# Obtain coordinates for our spatial data\ncoordinates &lt;- GetTissueCoordinates(seurat_obj)\n\nLet’s get an intuition for what this data looks like:\n\n# Inspect the coordinates table\nView(coordinates)\n\nWe have subsetted the first few dozen lines in the table below:\n\n\n\n\n\n\nThe x and y values correspond to the spot in pixel space that Seurat will be using.\nWe can compare the original image to the boundaries of the slide area to the coordinates obtained from the data.\n\n# Create plot with coordinates\ncoordinate_plot &lt;- ggplot(coordinates) +\n  geom_point(aes(x = x, y = y), size = 0.0001, color = \"cornflowerblue\")\n\n# Read in and orient the low resolution image\nlowres_image &lt;- image_read(\"data/fresh_frozen/spatial/tissue_lowres_image.png\") %&gt;% \n  image_rotate(degrees = 270) %&gt;% \n  as.raster(interpolate = TRUE) %&gt;% \n  rasterGrob()\n  \n# Read in and orient the detected tissue image\ndetected_image &lt;- image_read(\"data/fresh_frozen/spatial/detected_tissue_image.jpg\") %&gt;% \n  image_rotate(degrees = 90) %&gt;% \n  image_flop() %&gt;% \n  as.raster(interpolate = TRUE) %&gt;% \n  rasterGrob()\n\n# Plot three image images next to each other\nplot_grid(lowres_image, detected_image, coordinate_plot, nrow = 1, align = 'h')"
  },
  {
    "objectID": "lessons/Aside_subsetting_slide.html#array-coordinate-space",
    "href": "lessons/Aside_subsetting_slide.html#array-coordinate-space",
    "title": "Subsetting a Slide",
    "section": "Array Coordinate Space",
    "text": "Array Coordinate Space\nLet’s dig a bit deeper into how the spatial data is stored. The storage of the data comes from a parquet file that is provided with the data. We can read this parquet file using read_parquet from the arrow package:\n\n# Read parquet file\nparquet_df &lt;- read_parquet(\"data/fresh_frozen/binned_outputs/square_016um/spatial/tissue_positions.parquet\")\n\nWe can inspect what this parquet file looks like with:\n\n# Inspect parquet file\nView(parquet_df)\n\nThe first few dozen lines will look like:\n\n\n\n\n\n\nIn order to get a sense for this table, let’s investigate each column:\n\nbarcode - This is the barcode for the square on the slide. The format is:\n\n[ident]_[bin_size]_[array_row]_[array_col]-[suffix] where:\n\nident - The ident\nbin_size - The size of the bin\narray_row - The row number in the array for a given bin size\narray_col - The column number in the array for a given bin size\nsuffix - An optional suffix reserved for technical reasons (usually is -1)\n\n\nin_tissue - A binary descriptor for whether Space Ranger believes this is in the tissue or not\n\n0 - Not in the tissue\n1 - In the tissue\n\narray_row - The row number in the array for a given bin size\narray_col - The column number in the array for a given bin size\npxl_row_in_fullres - Location of row in pixel space\npxl_col_in_fullres - Location of column in pixel space"
  },
  {
    "objectID": "lessons/Aside_subsetting_slide.html#drawing-connections-between-the-two-coordinate-spaces",
    "href": "lessons/Aside_subsetting_slide.html#drawing-connections-between-the-two-coordinate-spaces",
    "title": "Subsetting a Slide",
    "section": "Drawing Connections Between the Two Coordinate Spaces",
    "text": "Drawing Connections Between the Two Coordinate Spaces\nThe array_row and array_col are directly tied to pxl_row_in_fullres and pxl_col_in_fullres, respectively. However the data has undergone an affine transformation within Space Ranger that considers a scale factor (how many pixels per bin), an offset and a rotation. In short, the array_row and array_col are ralated to pxl_row_in_fullres and pxl_col_in_fullres and the parquet file ties them together. Let’s evaluate this by looking at the first line from the parquet file:\n\noptions(pillar.sigfig = 7)\nparquet_df[parquet_df$barcode == \"s_016um_00107_00066-1\",]\n\n# A tibble: 1 × 6\n  barcode    in_tissue array_row array_col pxl_row_in_fullres pxl_col_in_fullres\n  &lt;chr&gt;          &lt;int&gt;     &lt;int&gt;     &lt;int&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1 s_016um_0…         1       107        66           2977.619           23843.36\n\n\nNow let’s look at that same cell in our coordinates object\n\ncoordinates[coordinates$cell == \"s_016um_00107_00066-1\",]\n\n                             x        y                  cell\ns_016um_00107_00066-1 2977.619 23843.36 s_016um_00107_00066-1\n\n\nWe can observe that pxl_row_in_fullres in the parquet file is the x column from Seurat’s GetTissueCoordinates() function and pxl_col_in_fullres in the parquet file is the y column from Seurat’s GetTissueCoordinates() function."
  },
  {
    "objectID": "lessons/Aside_subsetting_slide.html#setting-variables",
    "href": "lessons/Aside_subsetting_slide.html#setting-variables",
    "title": "Subsetting a Slide",
    "section": "Setting variables",
    "text": "Setting variables\nWe are going to set-up the the variables that we would like to loop through (bin size and sample) and also set our boundaries for where to subset our sample for. The index of the folders vector is the sample index for the boundary vectors (x_min, x_max, y_min, y_max).For example, the xmin of -Inf corresponds to the fresh_frozen sample while the xmin of 7205.1 corresponds to the fixed_frozen sample.\n\n# DO NOT RUN\n\nbins &lt;- c(\"008\", \"016\")\nfolders &lt;- c(\"fresh_frozen\", \"fixed_frozen\")\nx_min &lt;- c(-Inf, 7205.1) \nx_max &lt;- c(15114, Inf)\ny_min &lt;- c(-Inf, -1592)\ny_max &lt;- c(21517, 17735)\n\nThe code below will allow us to loop through the different samples and bin sizes, adding them to a data_filtered/.\n\n# DO NOT RUN\n\nfor (folder in folders) {\n  dir.create(paste0(\"data_filtered/\", folder, \"/binned_outputs/\"), recursive = TRUE)\n  for (bin in bins) {\n    \n    path_bin &lt;- paste0(\"data_filtered/\", folder, \"/binned_outputs/square_\", bin, \"um\")\n    dir.create(path_bin, recursive = TRUE)\n    \n    # Copy spatial images from original folder\n    dir.create(paste0(path_bin, \"/spatial\"), recursive = TRUE)\n    \n    path_json &lt;- paste0(\"data/\", folder, \"/binned_outputs/square_\", bin, \n                      \"um/spatial/scalefactors_json.json\")\n    path_parq &lt;- paste0(\"data/\", folder, \"/binned_outputs/square_\", bin, \n                      \"um/spatial/tissue_positions.parquet\")\n    path_png  &lt;- paste0(\"data/\", folder, \"/binned_outputs/square_\", bin, \n                      \"um/spatial/tissue_lowres_image.png\")\n    files_spatial &lt;- c(path_json, path_parq, path_png)\n    file.copy(files_spatial,paste0(path_bin, \"/spatial\"))\n  \n    # Load object\n    obj &lt;- Load10X_Spatial(\n      data.dir = paste0(\"data/\", folder),\n      bin.size = c(as.integer(bin)),\n      slice = folder)\n  \n    # Cells to keep based on coordinates\n    coords &lt;- GetTissueCoordinates(obj)\n    cells &lt;- coords %&gt;% \n      subset((x &gt; x_min[which(folders == folder)] & x &lt; x_max[which(folders == folder)]) & \n             (y &gt; y_min[which(folders == folder)] & y &lt; y_max[which(folders == folder)])) %&gt;% \n      row.names()\n  \n    # Subset object\n    obj$filter &lt;- TRUE\n    obj@meta.data[cells, \"filter\"] &lt;- FALSE\n    obj_filt &lt;- subset(obj, filter == FALSE)\n  \n    p &lt;- SpatialFeaturePlot(obj, paste0(\"nCount_Spatial.\", bin, \"um\"), pt.size.factor = 3) +\n         SpatialFeaturePlot(obj_filt, paste0(\"nCount_Spatial.\", bin, \"um\"), pt.size.factor = 3)\n    print(p)\n  \n    path_h5 &lt;- paste0(path_bin, \"/filtered_feature_bc_matrix.h5\")\n    write10xCounts(path_h5,\n                   x=LayerData(obj_filt),\n                   barcodes=colnames(obj_filt),\n                   gene.id=rownames(obj_filt),\n                   version=\"3\",\n                   type=\"HDF5\",\n                   overwrite = TRUE)\n  \n    rm(obj)\n    rm(obj_filt)\n  }\n}"
  },
  {
    "objectID": "lessons/Aside_subsetting_slide.html#test-reading-in-fresh_frozen-bin-sizes",
    "href": "lessons/Aside_subsetting_slide.html#test-reading-in-fresh_frozen-bin-sizes",
    "title": "Subsetting a Slide",
    "section": "Test Reading in fresh_frozen Bin Sizes",
    "text": "Test Reading in fresh_frozen Bin Sizes\nIf we had run been able to run the above for loops, our directory structure would now look like:\nWith this directory structure, let’s go ahead and load in the “fresh_frozen” sample for the 16μm bin size:\n\n# DO NOT RUN\n\n# Load fresh_frozen 16μm\nfresh_16 &lt;- Load10X_Spatial(\n    data.dir = \"data_filtered/fresh_frozen\",\n    bin.size = 16,\n    slice = \"fresh\")\n\nNext we will load in the “fresh_frozen” sample for the 8μm bin size:\n\n# DO NOT RUN\n\n# Load fresh_frozen 8μm\nfresh_8 &lt;- Load10X_Spatial(\n    data.dir = \"data_filtered/fresh_frozen\",\n    bin.size = 8,\n    slice = \"fresh\")\n\nWe can confirm that the number of bins in the fresh_8 is greater than the number of bins in the fresh_16 as we would expect:\n\n# DO NOT RUN\n\n# Number of bins in the 8μm fresh_frozen sample\nncol(fresh_8)\n# Number of bins in the 16μm fresh_frozen sample\nncol(fresh_16)\n\nLastly, we can visualize both bin sizes for our “fresh_frozen” samples side-by-side using SpatialFeaturePlot():\n\n# DO NOT RUN\n\n# Compare SpatialFeaturePlot of fresh_8 and fresh_16\nSpatialFeaturePlot(fresh_8,  \"nCount_Spatial.008um\", pt.size.factor = 3) |\n  SpatialFeaturePlot(fresh_16,  \"nCount_Spatial.016um\", pt.size.factor = 3)"
  },
  {
    "objectID": "lessons/Aside_subsetting_slide.html#test-reading-in-fixed_frozen-bin-sizes",
    "href": "lessons/Aside_subsetting_slide.html#test-reading-in-fixed_frozen-bin-sizes",
    "title": "Subsetting a Slide",
    "section": "Test Reading in fixed_frozen Bin Sizes",
    "text": "Test Reading in fixed_frozen Bin Sizes\nWe will iterate those steps for the “fixed_frozen” sample:. First, we will read in the 16μm bin size:\n\n# DO NOT RUN\n\n# Load fixed_frozen 16μm\nfixed_16 &lt;- Load10X_Spatial(\n    data.dir = \"data_filtered/fixed_frozen\",\n    bin.size = 16,\n    slice = \"fixed\")\n\nNext, we will read in the 8μm bin size for the “fixed_frozen” sample:\n\n# DO NOT RUN\n\n# Load fixed_frozen 8μm\nfixed_8 &lt;- Load10X_Spatial(\n    data.dir = \"data_filtered/fixed_frozen\",\n    bin.size = 8,\n    slice = \"fixed\")\n\nOnce again, we will do a check to ensure that the number of bins in the fixed_8 is greater than the number of bins in the fixed_16 as we would expect:\n\n# DO NOT RUN\n\n# Number of bins in the 8μm fixed_frozen sample\nncol(fixed_8)\n# Number of bins in the 16μm fixed_frozen sample\nncol(fixed_16)\n\nLastly, we can check that both bin sizes have been subsetted correctly and view them with SpatialFeaturePlot():\n\n# DO NOT RUN\n\n# Compare SpatialFeaturePlot of fixed_8 and fixed_16\nSpatialFeaturePlot(fixed_8,  \"nCount_Spatial.008um\", pt.size.factor = 3) |\n  SpatialFeaturePlot(fixed_16,  \"nCount_Spatial.016um\", pt.size.factor = 3)"
  },
  {
    "objectID": "lessons/Aside_subsetting_slide.html#merging-the-8μm-bin-size",
    "href": "lessons/Aside_subsetting_slide.html#merging-the-8μm-bin-size",
    "title": "Subsetting a Slide",
    "section": "Merging the 8μm Bin Size",
    "text": "Merging the 8μm Bin Size\nFirst, we will merge the 8μm bin size:\n\n# DO NOT RUN\n\n# Merge two sample together\nmerged_8 &lt;- merge(fixed_8, fresh_8)\n\nHowever, when we use the merge() function in Seurat, it keeps the counts matrices of previously fixed_8 and fresh_8 in separate layers. We would like them to be in the same layer for our analysis, so we will use the JoinLayers() function from Seurat to do this:\n\n# DO NOT RUN\n\n# Combines combines the count matrices from different layers into a single layer\nmerged_8 &lt;- JoinLayers(merged_8)\n\nWe would like to visualize our data to ensure that everything looks like it was done correctly, but in order to do this appropriately, we will need to normalize the data using Seuart’s NormalizeData() function:\n\n# DO NOT RUN\n\n# Normalize data for the merged 8μm bin size\nmerged_8 &lt;- NormalizeData(merged_8)\n\nWe can visualize a gene that we are potentially interested in “Cck” using SpatialFeaturePlot():\n\n# DO NOT RUN\n\n# Visualize Cck for our merged 8μm bin size\nSpatialFeaturePlot(merged_8, \n                   features = \"Cck\", \n                   pt.size.factor = 3)"
  },
  {
    "objectID": "lessons/Aside_subsetting_slide.html#merging-the-16μm-bin-size",
    "href": "lessons/Aside_subsetting_slide.html#merging-the-16μm-bin-size",
    "title": "Subsetting a Slide",
    "section": "Merging the 16μm Bin Size",
    "text": "Merging the 16μm Bin Size\nNow, we will merge the 16μm bin size following the same steps:\n\n# DO NOT RUN\n\n# Merge two sample together\nmerged_16 &lt;- merge(fixed_16, fresh_16)\n\nAgain, we will use the JoinLayers() to combine the counts matrices of the previously fixed_16 and fresh_16 :\n\n# DO NOT RUN\n\n# Combines combines the count matrices from different layers into a single layer\nmerged_16 &lt;- JoinLayers(merged_16)\n\nWe will normalize our 16μm data for visualization with Seuart’s NormalizeData() function:\n\n# DO NOT RUN\n\n# Normalize data for the merged 16μm bin size\nmerged_16 &lt;- NormalizeData(merged_16)\n\nWe can visualize a gene that we are potentially interested in “Cck” using SpatialFeaturePlot() on the 16μm data:\n\n# DO NOT RUN\n\n# Visualize Cck for our merged 16μm bin size\nSpatialFeaturePlot(merged_16, \n                   features = \"Cck\", \n                   pt.size.factor = 3)\n\nAt this point we have successfully subsetted out data for two different bin sizes and from two separate samples while performing appropriate checks along the way to ensure that our subsetting has been done correctly."
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#metadata",
    "href": "lessons/02_preprocessing-of-data.html#metadata",
    "title": "Pre-processing of Spatial Data",
    "section": "Metadata",
    "text": "Metadata\n\nHuman CRCMouse Brain\n\n\nMatched control and cancerous colon sample from 58 year old female in stage IV-A.\n\nNatural (control)\nColorectal Cancer\n\nWith the associated paper\n\n\nA mouse brain (fresh frozen) was obtained from Charles River Laboratories.\nStrain: C57BL/6 Sex: Male Age: 8 weeks Sample preparation\nA 10 µm section was taken with a cryostat (Epredia CryoStar NX70). Tissue block preparation, sectioning, H&E staining, and imaging followed the Visium HD Fresh Frozen Tissue Preparation Handbook (CG000763).\nThe data was subset to a smaller cross-section of the brain in order to make it more manageable on local laptops. The instructions for how to subset a 10X Visium HD slides can be found here.",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#dowloading-the-r-project-and-data",
    "href": "lessons/02_preprocessing-of-data.html#dowloading-the-r-project-and-data",
    "title": "Pre-processing of Spatial Data",
    "section": "Dowloading the R Project and Data",
    "text": "Dowloading the R Project and Data\nWe have assembled an R Project for you to download that includes the data along with a basic file structure for maintain good data management. It can be quite easy when starting a new analysis to want to dive right in and start analyzing your data. However, good data management practices occur at each step of data’s lifecycle. It is a good habit to begin by creating a basic directory structure to hold your data. Let’s start by download this R Project and data from here. Left-click on the link and select Save Link As.. or Download Linked File As.., then select a place on your computer where you would like to place this R Project.\nWe can open the R Project up and see that the provided file structure should look like:\nIf your R Project looks like below, then you are ready to start!\nTODO: Insert picture of what the R Project will look when it is ready to start\n\n\n\n\n\n\nExercise 1\n\n\n\nGiven the information that we know from the metadata, what might be some questions that we are interested in interrogating using our data?\n\n\n\n# Loading spatial files\n# Dec 2025\n\nlibrary(tidyverse)\nlibrary(Seurat)",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#data-files",
    "href": "lessons/02_preprocessing-of-data.html#data-files",
    "title": "Pre-processing of Spatial Data",
    "section": "Data Files",
    "text": "Data Files\nTo load our data, we are going to make use of the function Load10X_Spatial(). The input needed for this function comes from the output generated by SpaceRanger, including both the feature matrix and low-resolution tissue image. Once supplied, a Seurat object that contains our counts matrix and image is created.\nThere are 3 main arguments that we will be utilizing for this step:\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndata.dir\nDirectory containing the H5 file specified by filename and the image data in a subdirectory called spatial\n\n\nbin.size\nSpecifies the bin sizes to read in (defaults to c(16, 8))\n\n\nslice\nName for the stored image of the tissue slice\n\n\n\n\n\n\n\n\n\nUsing ? to look up function arguments\n\n\n\n\n\nIf you are ever unsure what parameters you can supply to a function, you make use of the ? call in R. This will bring up the manual page for the function while will provide more details on what each variable is used for.\n\n?Load10X_Spatial\n\n\n\n\nBefore loading in the data, let us take a look at the files we will supplying to the function. In particular, let us take a look at sample data/P5CRC which is the path would supply as data.dir in the Load10X_Spatial() function.\n\n\ndata/P5CRC/\n├── Visium_HD_Human_Colon_Cancer_P5_binned_outputs.tar.gz\n├── Visium_HD_Human_Colon_Cancer_P5_spatial.tar.gz\n├── binned_outputs\n│   ├── square_002um\n│   ├── square_008um\n│   └── square_016um\n└── spatial\n    ├── aligned_fiducials.jpg\n    ├── aligned_tissue_image.jpg\n    ├── cytassist_image.tiff\n    ├── detected_tissue_image.jpg\n    ├── tissue_hires_image.png\n    └── tissue_lowres_image.png\n\n\nIn the Visium HD assay, SpaceRanger bins the image into 2µm x 2µm, 8µm x 8µm, and 16µm x 16µm bins. The output from each of these resolution is found in the binned_outputs folder.\n\n\n\n\n\n\nChoosing your bin size\n\n\n\nTODO\n\nDepends on the size of celltypes in your dataset\nMention that we will discuss segmentation more in future lessons",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#creating-seurat-object",
    "href": "lessons/02_preprocessing-of-data.html#creating-seurat-object",
    "title": "Pre-processing of Spatial Data",
    "section": "Creating Seurat Object",
    "text": "Creating Seurat Object\nNow that we understand the input needed for the Load10X_Spatial() function, let’s use it to create a Seurat object called crc. We will specify that we want to load in the 8um and 16um bin sizes at the same time. Typically you would only load in one bin size, but for the purposes of better understanding bins and our Seurat object we will load both here.\n\ncrc &lt;- Load10X_Spatial(\n  data.dir = \"data/P5CRC/\",\n  bin.size = c(8, 16),\n  slice = \"P5CRC\")\n\nNow we can examine its major features, which we will add to and alter throughout the lesson:\n\ncrc\n\nAn object of class Seurat \n36170 features across 678003 samples within 2 assays \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 1 other assay present: Spatial.016um\n 2 spatial fields of view present: P5CRC.008um P5CRC.016um",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#anatomy-of-a-seurat-object",
    "href": "lessons/02_preprocessing-of-data.html#anatomy-of-a-seurat-object",
    "title": "Pre-processing of Spatial Data",
    "section": "Anatomy of a Seurat Object",
    "text": "Anatomy of a Seurat Object\nAs we can see from our Seurat callout, there are a lot of different slots inside our object. Here, we will go through each of the major components of a Seurat object and how you would access key pieces of information.\n\nAssaysFeatures and CellsLayersSpatial fieldMetadataIdents\n\n\nAssays are where we can store different counts matrices - we are not forced to keep the same features and variable genes across assays. Each assay will contain it’s own Layers that can be distinct from other assays in the object. This is useful in several different cases:\n\nMulti-modal assays, where you can keep the expression matrices for RNA, ATAC, or protein in a single Seurat object\nStoring counts matrices from a variety of different normalization techniques\nBatch integration methods will sometimes generate a transformed counts matrix\n\nHere we can print the different assays that exist within our crc object:\n\nAssays(crc)\n\n[1] \"Spatial.008um\" \"Spatial.016um\"\n\n\nWe have 2 distinct assays for the different bin sizes, which makes sense because we have different count matrices for our cells based upon the bin size that was selected.\nThe DefaultAssay() function shows us which assay information will be used in other Seurat function calls, unless explicitly specified otherwise.\n\nDefaultAssay(crc)\n\n[1] \"Spatial.008um\"\n\n\nWe can also change what our default assay is. Let’s set it to the 016um bins:\n\nDefaultAssay(crc) &lt;- \"Spatial.016um\"\ncrc\n\nAn object of class Seurat \n36170 features across 678003 samples within 2 assays \nActive assay: Spatial.016um (18085 features, 0 variable features)\n 1 layer present: counts\n 1 other assay present: Spatial.008um\n 2 spatial fields of view present: P5CRC.008um P5CRC.016um\n\n\nNow we see that the callout says: Active assay: Spatial.016um\n\n\nOur count matrices function as any other matrix does, with rows and columns.\nIn Seurat, the rows correspond to Features. In the case of spatial transcriptomics, our features are genes. In other experiments, features could refer to chromatin peaks or proteins. The important thing to keep in mind is what technology you are using. Since this is a Visium HD dataset, we are quantifying RNA expression (genes).\nWe can see what the first few genes/features in our count matrix are:\n\nFeatures(crc) %&gt;% head()\n\n[1] \"SAMD11\"  \"NOC2L\"   \"KLHL17\"  \"PLEKHN1\" \"PERM1\"   \"HES4\"   \n\n\nAs well as see the number of genes that are found in each of our assays:\n\nnrow(crc[[\"Spatial.008um\"]])\n\n[1] 18085\n\nnrow(crc[[\"Spatial.016um\"]])\n\n[1] 18085\n\n\nThe **columns* correspond to Cells (or samples as it appears in the callout).\nWe can see what the first few cells in our count matrix are:\n\nCells(crc) %&gt;% head()\n\n[1] \"s_016um_00052_00082-1\" \"s_016um_00396_00063-1\" \"s_016um_00297_00147-1\"\n[4] \"s_016um_00347_00254-1\" \"s_016um_00299_00088-1\" \"s_016um_00050_00315-1\"\n\n\nAs well as see the number of cells that are found in each of our assays:\n\nncol(crc[[\"Spatial.008um\"]])\n\n[1] 541968\n\nncol(crc[[\"Spatial.016um\"]])\n\n[1] 136035\n\n\n\n\n\n\n\n\nBin size\n\n\n\nDid you notice that the number of cells is different between our 8um and 16um bins?\nThis is why the bin value matters, it determines how many “cells” are ultimately generated. Where a smaller bin size results in more spots.\n\n\n\n\nLayers are our count matrices.\n\nLayers(crc)\n\n[1] \"counts\"\n\n\nBy default, Seurat uses the following naming convention for the counts matrices within an Assay:\n\n\n\nLayer\nDescription\n\n\n\n\ncounts\nRaw counts\n\n\ndata\nNormalized counts\n\n\nscale.data\nScaled‑normalized counts\n\n\n\nYou may notice that our Seurat object only contains counts right now. This is because we have not run any normalization steps yet (we will discuss how to do so in future lessons).\nUsing the LayerData() function we can access the entire counts matrix. Furthermore, we can specify the assay if we would prefer to not use the DefaultAssay.\n\nLayerData(crc, \n          assay = \"Spatial.016um\", \n          layer = \"count\")[1:5, 1:5]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ns_016um_00052_00082-1\ns_016um_00396_00063-1\ns_016um_00297_00147-1\ns_016um_00347_00254-1\ns_016um_00299_00088-1\n\n\n\n\nSAMD11\n0\n0\n0\n0\n0\n\n\nNOC2L\n1\n1\n0\n0\n0\n\n\nKLHL17\n0\n0\n0\n0\n0\n\n\nPLEKHN1\n0\n0\n0\n0\n0\n\n\nPERM1\n0\n0\n0\n0\n0\n\n\n\n\n\nBy printing the first 5 features and cells in our object (for easier visualization). We can see that we are working with whole numbers which reinforces the idea that this is the raw data, with no transformations having been applied.\n\n\nWe do not just have expression data associated with our sample, we also have the spatial slide that comes with its own set of values and information.\nFor example we can grab the x,y coordinates of each bin using the GetTissueCoordinates() function.\n\n\n                             x        y                  cell\ns_016um_00052_00082-1 60930.62 49099.34 s_016um_00052_00082-1\ns_016um_00396_00063-1 40823.45 48072.16 s_016um_00396_00063-1\ns_016um_00297_00147-1 46628.74 52957.09 s_016um_00297_00147-1\ns_016um_00347_00254-1 43732.54 59222.16 s_016um_00347_00254-1\ns_016um_00299_00088-1 46497.72 49509.67 s_016um_00299_00088-1\ns_016um_00050_00315-1 61103.62 62715.76 s_016um_00050_00315-1\n\n\n\n\n\n\n\n\nOr visualize what our slide looks like with SpatialDimPlot():\n\nSpatialDimPlot(crc)\n\n\n\n\n\n\n\n\n\n\nSeurat automatically creates some metadata for each of the cells when the object is created. This information is stored in the @meta.data slot within the Seurat object. The rownames are automatically set to be the cell names.\n\ncrc@meta.data %&gt;% head()\n\n\n\n\n\n\n\nWhat does each column represent?\n\n\n\nColumn\nDescription\n\n\n\n\norig.ident\nSample identity if known; defaults to “s”\n\n\nnCount_RNA\nNumber of UMIs per cell\n\n\nnFeature_RNA\nNumber of genes detected per cell\n\n\n\nWhile it may seem intimidating at first, the important thing to remember is that this is a dataframe. Therefore can modify and work with this dataframe just like we would any other in R! For example, we can set our orig.ident column to be our sample name rather than “s”.\n\ncrc@meta.data$orig.ident &lt;- \"P5CRC\"\n\n\ncrc@meta.data %&gt;% head()\n\n\n\n\n\n\n\nAdditionally, we do not have use the @meta.data each time we want to access a single column. We can use the $ follow by the column name as a shorthand.\n\ncrc$nCount_Spatial.008um %&gt;% head()\n\ns_008um_00602_00290-1 s_008um_00789_00234-1 s_008um_00728_00006-1 \n                  225                    76                   215 \ns_008um_00526_00291-1 s_008um_00681_00396-1 s_008um_00078_00444-1 \n                   57                    74                    65 \n\n\n\n\nTODO\n\nIdents(crc) &lt;- \"orig.ident\"\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nTODO Exercise 1",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#downloading-the-r-project-and-data",
    "href": "lessons/02_preprocessing-of-data.html#downloading-the-r-project-and-data",
    "title": "Pre-processing of Spatial Data",
    "section": "Downloading the R Project and Data",
    "text": "Downloading the R Project and Data\nWe have assembled an R Project for you to download that includes the data along with a basic file structure for maintain good data management. It can be quite easy when starting a new analysis to want to dive right in and start analyzing your data. However, good data management practices occur at each step of data’s lifecycle. It is a good habit to begin by creating a basic directory structure to hold your data. Let’s start by download this R Project and data from here. Left-click on the link and select Save Link As.. or Download Linked File As.., then select a place on your computer where you would like to place this R Project.\nWe can open the R Project up and see that the provided file structure should look like:\nIf your R Project looks like below, then you are ready to start!\nTODO: Insert picture of what the R Project will look when it is ready to start\n\n\n\n\n\n\nExercise 1\n\n\n\nGiven the information that we know from the metadata, what might be some questions that we are interested in interrogating using our data?\n\n\n\n# Loading spatial files\n# Dec 2025\n\nlibrary(tidyverse)\nlibrary(Seurat)",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#using-a-for-loop",
    "href": "lessons/02_preprocessing-of-data.html#using-a-for-loop",
    "title": "Pre-processing of Spatial Data",
    "section": "Using a for Loop",
    "text": "Using a for Loop\nIn practice, you will likely have several samples that you will need to read in data for, and that can get tedious and error-prone if you do it one at a time. So, to make the data import into R more efficient we can use a for loop, which will iterate over a series of commands for each of the inputs given and create Seurat objects for each of our samples.\nIn R, the for loop has the following structure/syntax:\n\n## DO NOT RUN\n\nfor (variable in input){\n    command1\n    command2\n    command3\n}\n\nToday we will use it to iterate over the two sample folders and execute commands for each sample as we did above for a single sample:\n\nCreate the Seurat objects from the SpaceRanger data (Load10X_Spatial())\nSet orig.ident to be our sample\n\nOnce those steps run, we will store the newly generated Seurat object to a list called list_seurat so that we can eventually merge both samples together.\nWe will be using a bin size of 8um for the remainder of this workshop\n\nsamples &lt;- c(\"P5CRC\", \"P5NAT\")\nlist_seurat &lt;- list()\n\nfor (sample in samples) {\n  \n  # Path to data directory\n  data_dir &lt;- paste0(\"data/\", sample)\n  # Create seurat object and set orig ident to be sample\n  seurat &lt;- Load10X_Spatial(data.dir = data_dir,\n                            bin.size = c(8),\n                            slice = sample)\n  seurat$orig.ident &lt;- sample\n  \n  # Store seurat object in our list\n  list_seurat[[sample]] &lt;- seurat\n}\n\nTo confirm that we succesfully loaded both samples in, we can take a look at the contents of list_seurat. We should see that there are two Seurat objects in our list that correspond to each sample.\n\nlist_seurat\n\n$P5CRC\nAn object of class Seurat \n18085 features across 541968 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 1 spatial field of view present: P5CRC.008um\n\n$P5NAT\nAn object of class Seurat \n18085 features across 435773 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 1 spatial field of view present: P5NAT.008um\n\n\nThis is exactly what we had hoped to see! So now we can move on to the next step which is merging the sample together into a singular Seurat object.\n\n\n\n\n\n\nMerging vs. Integration\n\n\n\n\n\nA common point of confusion is the distinction between integration and merging. In the field, integration is considered to be modifying either your counts or latent space in a way to correct for a batch variable. Whereas what we are doing now is merging or concatenating multiple samples together. This process of merging does not transform the values in the count matrices.",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#creating-the-seurat-object",
    "href": "lessons/02_preprocessing-of-data.html#creating-the-seurat-object",
    "title": "Pre-processing of Spatial Data",
    "section": "Creating the Seurat Object",
    "text": "Creating the Seurat Object\nNow that we understand the input needed for the Load10X_Spatial() function, let’s use it to create a Seurat object called crc. We will specify that we want to load in the 8µm and 16µm bin sizes at the same time.\nTypically you would only load in one bin size, but for the purposes of better understanding bins and our Seurat object we will load both here.\n\ncrc &lt;- Load10X_Spatial(\n  data.dir = \"data/P5CRC/\",\n  bin.size = c(8, 16),\n  slice = \"P5CRC\")\n\nWe can print out some basic information of our Seurat object to examine its data structure. We will do this frequently throughout the workshop to understand how our data changes with each step of the workflow.\n\ncrc\n\nAn object of class Seurat \n36170 features across 678003 samples within 2 assays \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 1 other assay present: Spatial.016um\n 2 spatial fields of view present: P5CRC.008um P5CRC.016um",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#merge-datasets-together",
    "href": "lessons/02_preprocessing-of-data.html#merge-datasets-together",
    "title": "Pre-processing of Spatial Data",
    "section": "Merge Datasets Together",
    "text": "Merge Datasets Together\nWe merge samples together because it make it easier to run the QC steps for both sample groups together. It also enables us to easily compare the data quality for all cells at one time\nTo create this combined Seurat object, we use the merge() function. Because the same cell IDs can be used for different samples, we add a sample-specific prefix to each of our cell IDs using the add.cell.id argument to ensure the cell names are unique.\n\nseurat_merged &lt;- merge(x = list_seurat[[\"P5CRC\"]],\n                       y = list_seurat[[\"P5NAT\"]],\n                       add.cell.id = c(\"P5CRC\", \"P5NAT\"))\nseurat_merged\n\nAn object of class Seurat \n18085 features across 977741 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 2 layers present: counts.1, counts.2\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nFrom the callout we can see that we now have: 2 layers present: counts.1, counts.2\nWhich we also see represented if we look at our Layers()\n\nLayers(seurat_merged)\n\n[1] \"counts.1\" \"counts.2\"\n\n\nHowever, we do not want to have two distinct raw counts matrices (counts.1 and counts.2. We want the counts for each sample to be concatenated together. This would be a single, large count matrix that represent each cell in the dataset. Seurat’s function JoinLayers() allows us to do just this.\n\nseurat_merged &lt;- JoinLayers(seurat_merged)\nseurat_merged\n\nAn object of class Seurat \n18085 features across 977741 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nNow we have a singular counts matrix.\n\n\n\n\n\n\nWhat if I am merging more than two samples?\n\n\n\n\n\nSeurat has functionality to merge many samples together. You can do this quite easily by adding all sample objects to the y argument in a vector format. An example is provided below, assuming you use the list structured we used previously:\n\n## DO NOT RUN\nmerged_seurat &lt;- merge(x = seurat_list[[1]], \n                       y = seurat_list[[2:length(seurat_list)]],\n                       add.cell.id = names(seurat_list))",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_preprocessing-of-data.html#evaluating-merged_seurat",
    "href": "lessons/02_preprocessing-of-data.html#evaluating-merged_seurat",
    "title": "Pre-processing of Spatial Data",
    "section": "Evaluating merged_seurat",
    "text": "Evaluating merged_seurat\nLet’s also double check that we have the correct number of cells. First, let us see what the number of cells was for each sample:\n\nncol(list_seurat[[\"P5CRC\"]])\n\n[1] 541968\n\nncol(list_seurat[[\"P5NAT\"]])\n\n[1] 435773\n\n\nThe sum of these values is:\n\n541968 + 435773\n\n[1] 977741\n\n\nWhich is the same as the number of samples in our Seurat callout!\n\nseurat_merged\n\nAn object of class Seurat \n18085 features across 977741 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nIf we look at the metadata of the merged object we should be able to see the prefixes in the rownames (Cells) as well as the updated orig.ident we set in the for loop earlier.\n\n# Check that the merged object has the appropriate sample-specific prefixes\nhead(seurat_merged@meta.data)\n\n                            orig.ident nCount_Spatial.008um\nP5CRC_s_008um_00602_00290-1      P5CRC                  225\nP5CRC_s_008um_00789_00234-1      P5CRC                   76\nP5CRC_s_008um_00728_00006-1      P5CRC                  215\nP5CRC_s_008um_00526_00291-1      P5CRC                   57\nP5CRC_s_008um_00681_00396-1      P5CRC                   74\nP5CRC_s_008um_00078_00444-1      P5CRC                   65\n                            nFeature_Spatial.008um\nP5CRC_s_008um_00602_00290-1                    199\nP5CRC_s_008um_00789_00234-1                     71\nP5CRC_s_008um_00728_00006-1                    196\nP5CRC_s_008um_00526_00291-1                     40\nP5CRC_s_008um_00681_00396-1                     71\nP5CRC_s_008um_00078_00444-1                     57\n\ntail(seurat_merged@meta.data)\n\n                            orig.ident nCount_Spatial.008um\nP5NAT_s_008um_00536_00521-1      P5NAT                  158\nP5NAT_s_008um_00148_00248-1      P5NAT                  252\nP5NAT_s_008um_00353_00477-1      P5NAT                  284\nP5NAT_s_008um_00797_00672-1      P5NAT                    1\nP5NAT_s_008um_00373_00222-1      P5NAT                  514\nP5NAT_s_008um_00595_00611-1      P5NAT                  101\n                            nFeature_Spatial.008um\nP5NAT_s_008um_00536_00521-1                    116\nP5NAT_s_008um_00148_00248-1                    222\nP5NAT_s_008um_00353_00477-1                    210\nP5NAT_s_008um_00797_00672-1                      1\nP5NAT_s_008um_00373_00222-1                    436\nP5NAT_s_008um_00595_00611-1                     91\n\n\nLastly we want to make sure that the Idents of our cells is a useful piece of information, for example like orig.ident, which contains our sample IDs.\n\nIdents(seurat_merged) &lt;- \"orig.ident\"\n\n\n\n\n\n\n\nExercise 3\n\n\n\nTODO Exercise 3",
    "crumbs": [
      "Day 1:",
      "Pre-processing of Spatial Data"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#number-of-cells",
    "href": "lessons/03_quality-control.html#number-of-cells",
    "title": "Quality Control",
    "section": "Number of Cells",
    "text": "Number of Cells\n\nggplot(meta) +\n  geom_bar(aes(x = orig.ident, fill = orig.ident),\n           color = \"black\") +\n  geom_text(aes(x = orig.ident, label=after_stat(count)), \n            stat='count', vjust=-1) +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 2: Number of cells in the dataset, split by sample",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#umi-counts-transcripts-per-cell",
    "href": "lessons/03_quality-control.html#umi-counts-transcripts-per-cell",
    "title": "Quality Control",
    "section": "UMI Counts (Transcripts) per Cell",
    "text": "UMI Counts (Transcripts) per Cell\nTODO\n\ntalk about celltypes and how we see clear structure of certain cells with higher nUMIs\nCut-off of 10 for both samples\n\nWe expect to see a bimodal distribution, with one peak representing bins containing lower-quality cells with fewer UMIs and another peak representing bins containing healthy cells with more UMIs. Ideally, the peak representing lower-quality and dying cells is small and the peak representing healthy cells is large.\nThis is the number of unique transcripts detected per bin. Because the bins are very small, this number is less than what we would expect for non-spatial scRNA-seq data.\n\nSpatial OverlayBefore Filtration DensityAfter Filtration Density\n\n\n\nSpatialFeaturePlot(seurat_merged, \n                   \"nCount_Spatial.008um\",\n                   pt.size.factor = 3,\n                   image.alpha = 0,\n                   max.cutoff = 2000)\n\n\n\n\n\n\n\nFigure 3: Number of UMIs overlaid over spatial slide\n\n\n\n\n\n\n\n\nggplot(meta) +\n  geom_density(aes(x = nCount_Spatial.008um, fill = orig.ident),\n               alpha = 0.4,\n               color = \"black\") +\n  geom_vline(xintercept = 10, color = \"pink\") +\n  geom_vline(xintercept = 10, color = \"lightblue\") +\n  scale_x_log10() +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 4: Number of UMIs density\n\n\n\n\n\n\n\n\nmeta_filt &lt;- subset(meta,\n  ((orig.ident == \"P5CRC\") & (nCount_Spatial.008um &gt; 10)) |\n  ((orig.ident == \"P5NAT\") & (nCount_Spatial.008um &gt; 10)))\n\nggplot(meta_filt) +\n  geom_density(aes(x = nCount_Spatial.008um,\n                     fill = orig.ident),\n                 alpha = 0.4,\n                 color = \"black\") +\n  geom_vline(xintercept = 10, color = \"pink\") +\n  geom_vline(xintercept = 10, color = \"lightblue\") +\n  scale_x_log10() +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 5: Number of UMIs density after filtration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample specific values\n\n\n\n\n\nA commonly asked question is if you have to use the same threshold values across all your samples. We recommend that you follow what the data is telling you and do it on a per sample basis. Ultimately the end goal is to retain high-quality bins, even if that means using different values for each sample.",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#genes-detected-per-cell",
    "href": "lessons/03_quality-control.html#genes-detected-per-cell",
    "title": "Quality Control",
    "section": "Genes Detected per Cell",
    "text": "Genes Detected per Cell\nWe have similar expectations for gene detection as for UMI detection, although it may be a bit lower than UMIs.\nThis is the number of unique genes detected per bin. Again, because the bins are very small, this number is less than what we would expect for non-spatial scRNA-seq data.\n\nSpatial OverlayBefore Filtration DensityAfter Filtration Density\n\n\n\nSpatialFeaturePlot(seurat_merged, \n                   \"nFeature_Spatial.008um\",\n                   pt.size.factor = 3,\n                   image.alpha = 0,\n                   max.cutoff = 1200)\n\n\n\n\n\n\n\nFigure 6: Number of features overlaid over spatial slide\n\n\n\n\n\n\n\n\nggplot(meta) +\n  geom_density(aes(x = nFeature_Spatial.008um,\n                     fill = orig.ident),\n                 alpha = 0.4,\n                 color = \"black\") +\n  geom_vline(xintercept = 15, color = \"pink\") +\n  geom_vline(xintercept = 10, color = \"lightblue\") +\n  scale_x_log10() +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 7: Number of features density\n\n\n\n\n\n\n\n\nmeta_filt &lt;- subset(meta,\n  ((orig.ident == \"P5CRC\") & (nFeature_Spatial.008um &gt; 15)) |\n  ((orig.ident == \"P5NAT\") & (nFeature_Spatial.008um &gt; 10)))\n\nggplot(meta_filt) +\n  geom_density(aes(x = nFeature_Spatial.008um,\n                     fill = orig.ident),\n                 alpha = 0.4,\n                 color = \"black\") +\n  geom_vline(xintercept = 15, color = \"pink\") +\n  geom_vline(xintercept = 10, color = \"lightblue\") +\n  scale_x_log10() +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 8: Number of features density after filtration",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#complexity-novelty-score",
    "href": "lessons/03_quality-control.html#complexity-novelty-score",
    "title": "Quality Control",
    "section": "Complexity (Novelty) Score",
    "text": "Complexity (Novelty) Score\nIf there are many captured transcripts (high nUMI) and a low number of genes detected in a bin, this likely means that you only captured a low number of genes and simply sequenced transcripts from those lower number of genes over and over again. These low complexity (low novelty) bins could represent a specific cell type (i.e. red blood cells, which lack a typical transcriptome), or could be due to an artifact or contamination. Generally, we expect the complexity score to be above 0.80 for good-quality bins.\nThe novelty score is computed as shown below:\n\\[\n\\text{Complexity Score} = \\frac{\\text{Number of Genes}}{\\text{Number of UMIs}}\n\\]\nWhich we can now calculate using R and store in our @meta.data:\n\n# Add number of genes per UMI for each cell to metadata\nseurat_merged$log10GenesPerUMI &lt;- log10(seurat_merged$nFeature_Spatial.008um) / \n                                  log10(seurat_merged$nCount_Spatial.008um)\n\n\nSpatial OverlayBefore Filtration DensityAfter Filtration Density\n\n\n\nSpatialFeaturePlot(seurat_merged, \n                   \"log10GenesPerUMI\",\n                   pt.size.factor = 3,\n                   image.alpha = 0,\n                   min.cutoff = 0.7)\n\n\n\n\n\n\n\nFigure 9: Complexity score overlaid over spatial slide\n\n\n\n\n\n\n\n\nmeta &lt;- seurat_merged@meta.data\nggplot(meta) +\n  geom_density(aes(x = log10GenesPerUMI,\n                   fill = orig.ident),\n                 alpha = 0.4,\n                 color = \"black\") +\n  geom_vline(xintercept = 0.80) +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 10: Complexity score density\n\n\n\n\n\n\n\n\nmeta_filt &lt;- subset(meta, log10GenesPerUMI &gt; 0.80)\nggplot(meta_filt) +\n  geom_density(aes(x = log10GenesPerUMI,\n                   fill = orig.ident),\n                 alpha = 0.4,\n                 color = \"black\") +\n  geom_vline(xintercept = 0.80) +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 11: Complexity score density after filtration",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#mitochondrial-counts-ratio",
    "href": "lessons/03_quality-control.html#mitochondrial-counts-ratio",
    "title": "Quality Control",
    "section": "Mitochondrial Counts Ratio",
    "text": "Mitochondrial Counts Ratio\nThis metric can identify whether there is a large amount of mitochondrial contamination from dead or dying cells. We define poor-quality samples for mitochondrial counts as bins which surpass the 0.2 mitochondrial ratio threshold, unless of course you are expecting this in your sample. This ratio is computed as:\n\\[\n\\text{Mitochondrial Ratio} =\n\\frac{\\text{Number of reads aligning to mitochondrial genes}}\n     {\\text{Total reads}}\n\\]\n\n\n\n\n\n\nThink about your biological question\n\n\n\n\n\nWhile using a baseline score of 0.2 is an acceptable threshold for removing high mitochondrial content cells, it is important to always go back to your original biological question. What samples are you working with? Do you expect there to be high values of mitochondria due to your experimental condition?\nFor example, if you were studying renal oncocytomas would you make this same choice? This disease is characterized as having aberrantly high mitochondrial expression, would it make sense to remove cells with high mitochondrial ratio?\n\n\n\n\n# Compute percent mito ratio\nseurat_merged$mitoRatio &lt;- PercentageFeatureSet(object = seurat_merged, \n                                                pattern = \"^MT-\")\nseurat_merged$mitoRatio &lt;- seurat_merged@meta.data$mitoRatio / 100\n\n\nSpatial OverlayBefore Filtration DensityAfter Filtration Density\n\n\n\nSpatialFeaturePlot(seurat_merged, \n                   \"mitoRatio\",\n                   pt.size.factor = 3,\n                   image.alpha = 0,\n                   max.cutoff = 0.5)\n\n\n\n\n\n\n\nFigure 12: Mitochondrial ratio overlaid over spatial slide\n\n\n\n\n\n\n\n\nmeta &lt;- seurat_merged@meta.data\nggplot(meta) +\n  geom_density(aes(x = mitoRatio,\n                   fill = orig.ident),\n                 alpha = 0.4,\n                 color = \"black\") +\n  geom_vline(xintercept = 0.25) +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 13: Mitochondrial ratio density\n\n\n\n\n\n\n\n\nmeta_filt &lt;- subset(meta, mitoRatio &lt; 0.25)\n\nggplot(meta_filt) +\n  geom_density(aes(x = mitoRatio,\n                   fill = orig.ident),\n                 alpha = 0.4,\n                 color = \"black\") +\n  geom_vline(xintercept = 0.25) +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 14: Mitochondrial ratio density after filtration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\n\nDo you notice a pattern in cells in regards to the number of UMIs and feature? Make a geom_point plots to compare these values on a per-cell basis and color each point by the mitochondrial ratio following the structure provided here:\n\n\n# Structure for making geom_point plot\n# Fill in values to answer the question\nseurat_merged@meta.data %&gt;%\n  # Sorting by mitoRatio to make high scores appear on top of the plot\n  arrange(mitoRatio) %&gt;%\n  ggplot() +\n  geom_point(aes(x = ?, \n                 y = ?,\n                 color = ?),\n             size = 0.5) +\n  # Setting limits so that outliers don't determine scale of the plot\n  ylim(0, 3500) + xlim(0, 3500) +\n  theme_bw()",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#violin-plots",
    "href": "lessons/03_quality-control.html#violin-plots",
    "title": "Quality Control",
    "section": "Violin Plots",
    "text": "Violin Plots\nLet’s start with a violin plot to look at the distribution of UMI counts and gene counts. The input is our post-filtered dataset.\n\np_ncount &lt;- VlnPlot(seurat_filtered, \n                    features = \"nCount_Spatial.008um\", \n                    pt.size = 0, group.by = 'orig.ident') +\n  NoLegend()\n\np_nfeats &lt;- VlnPlot(seurat_filtered, \n                    features = \"nFeature_Spatial.008um\", \n                    pt.size = 0, group.by = 'orig.ident') + \n  NoLegend()\n\np_ncount | p_nfeats\n\n\n\n\n\n\n\nFigure 15: Violin plot of nCounts and nFeatures after filtration\n\n\n\n\n\nWe see that both distributions have a similar peak but the nUMI distribution has a much longer tail. This is expected, because while the small physical size of the bins means that most genes will be detected only once or twice, a minority of bins under very transcriptionally active cells may exhibit multiple transcripts of the same gene.",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/03_quality-control.html#spatial-overlay",
    "href": "lessons/03_quality-control.html#spatial-overlay",
    "title": "Quality Control",
    "section": "Spatial Overlay",
    "text": "Spatial Overlay\nNext, we can look at the same metrics and the distribution on the actual image itself. Note that many spots have very few counts, in part due to low cellular density or cell types with low complexity in certain tissue regions.\n\nSpatialFeaturePlot(seurat_filtered, \n                   c(\"nFeature_Spatial.008um\", \"nCount_Spatial.008um\"),\n                   pt.size.factor = 3,\n                   image.alpha = 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  },
  {
    "objectID": "lessons/05_normalization_and_sketch_downsampling.html",
    "href": "lessons/05_normalization_and_sketch_downsampling.html",
    "title": "Normalization and Sketch Downsampling",
    "section": "",
    "text": "Approximate time: XY minutes"
  },
  {
    "objectID": "lessons/05_normalization_and_sketch_downsampling.html#why-should-we-normalize",
    "href": "lessons/05_normalization_and_sketch_downsampling.html#why-should-we-normalize",
    "title": "Normalization and Sketch Downsampling",
    "section": "Why Should We Normalize?",
    "text": "Why Should We Normalize?\nAn essential first step in the majority of mRNA expression analyses is normalization, whereby systematic variations are adjusted for to make expression counts comparable across genes and/or samples. The counts of mapped reads for each gene is proportional to the expression of RNA (“interesting”) in addition to many other factors (“uninteresting”). Normalization is the process of adjusting raw count values to account for the “uninteresting” factors.\nSequencing depth: Accounting for sequencing depth is necessary for comparison of gene expression between cells. In the example below, each gene appears to have doubled in expression in cell 2, however this is a consequence of cell 2 having twice the sequencing depth."
  },
  {
    "objectID": "lessons/05_normalization_and_sketch_downsampling.html#log-normalization-steps",
    "href": "lessons/05_normalization_and_sketch_downsampling.html#log-normalization-steps",
    "title": "Normalization and Sketch Downsampling",
    "section": "Log-normalization Steps",
    "text": "Log-normalization Steps\nVarious methods have been developed specifically for scRNA-seq normalization. Some simpler methods resemble what we have seen with bulk RNA-seq; the application of global scale factors adjusting for a count-depth relationship that is assumed common across all genes. However, if those assumptions are not true then this basic normalization can lead to over-correction for lowly and moderately expressed genes and, in some cases, under-normalization of highly expressed genes (Bacher R et al, 2017).\nRegardless of which method is used for normalization, it can be helpful to think of it as a two-step process (even though it is often described as a single step in most papers). The first is a scaling step and the second is a transformation.\n1. Scaling\nThe first step in normalization is to multiply each UMI count by a cell specific factor to get all cells to have the same UMI counts. Why would we want to do this? Different cells have different amounts of mRNA; this could be due to differences between cell types or variation within the same cell type depending on how well the chemistry worked in one drop versus another. In either case, we are not interested in comparing these absolute counts between cells. Instead we are interested in comparing concentrations, and scaling helps achieve this.\n2. Transformation\nThe next step is a transformation, and it is at this step where we can distinguish the simpler versus complex methods as mentioned above.\nSimple transformations are those which apply the same function to each individual measurement. Common examples include a log transform (which is applied in the original Seurat workflow), or a square root transform (less commonly used)."
  },
  {
    "objectID": "lessons/05_normalization_and_sketch_downsampling.html#perform-log-normalization",
    "href": "lessons/05_normalization_and_sketch_downsampling.html#perform-log-normalization",
    "title": "Normalization and Sketch Downsampling",
    "section": "Perform Log-normalization",
    "text": "Perform Log-normalization\nLet’s start by creating a new script for the normalization and integration steps. Create a new script (File -&gt; New File -&gt; R script), and save it as normalization_and_sketch.R.\nFor the remainder of the workflow we will be mainly using functions available in the Seurat package. Additionally, we will load in the seurat_filtered object we created in the previous lesson.\n\n# Normalization and Sketch Subsampling\n# Dec 2025\n\n# Load libraries\nlibrary(Seurat)\nlibrary(tidyverse)\nlibrary(scales)\n\nseurat_filtered &lt;- readRDS(\"data/seurat_filtered.RDS\")\nseurat_filtered\n\nAn object of class Seurat \n18085 features across 826613 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nBefore we make any comparisons across cells, we will apply a simple normalization with the NormalizeData() function.\n\n# Normalize the counts\nseurat_sketch &lt;- NormalizeData(seurat_filtered)\nseurat_sketch\n\nAn object of class Seurat \n18085 features across 826613 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 2 layers present: counts, data\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nAnd we can see that there is now a new data layer in the Seurat object.\n\n\n\n\n\n\nExercise 1\n\n\n\nExercise 1"
  },
  {
    "objectID": "lessons/05_normalization_and_sketch_downsampling.html#calculating-hvgs",
    "href": "lessons/05_normalization_and_sketch_downsampling.html#calculating-hvgs",
    "title": "Normalization and Sketch Downsampling",
    "section": "Calculating HVGs",
    "text": "Calculating HVGs\nHVGs are calculated using the FindVariableFeatures() function. Some key arguments supplied to this function are:\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nselection.method\nHow to choose top variable features. vst: Fits a line to log(variance) vs. log(mean) using loess, standardizes values, and computes variance after clipping (see clip.max).\n\n\nnfeatures\nNumber of features to select as top variable features; used when selection.method is dispersion or vst\n\n\n\n\n# Identify the most variable genes\nseurat_sketch &lt;- FindVariableFeatures(seurat_sketch, \n                     selection.method = \"vst\",\n                     nfeatures = 2000)\nseurat_sketch\n\nAn object of class Seurat \n18085 features across 826613 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 2000 variable features)\n 2 layers present: counts, data\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nWhen we examine our Seurat object, we see that FindVariableFeatures() has added 2,000 variable features - just as we specified with nfeatures.\nSeurat allows us to access the ranked highly variable genes with the VariableFeatures() function. Here we print the top 15:\n\n# Identify the 15 most highly variable genes\nranked_variable_genes &lt;- VariableFeatures(seurat_sketch)\ntop_genes &lt;- ranked_variable_genes[1:15]\ntop_genes\n\n [1] \"IGHG3\" \"IGHM\"  \"SPP1\"  \"IGLC7\" \"IGLC1\" \"SST\"   \"IGHG1\" \"INSL5\" \"CHGA\" \n[10] \"VIP\"   \"HBA2\"  \"GCG\"   \"CXCL8\" \"MMP12\" \"PYY\"  \n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nUsing GeneCards, look up one of the top genes and read more about its role and how it could possible relate to CRC."
  },
  {
    "objectID": "lessons/05_normalization_and_sketch_downsampling.html#downsampling",
    "href": "lessons/05_normalization_and_sketch_downsampling.html#downsampling",
    "title": "Normalization and Sketch Downsampling",
    "section": "Downsampling",
    "text": "Downsampling\nFor our dataset, we are going to downsample our dataset to 10,000 bins using the SketchData() function. The function takes a normalized single-cell dataset containing a set of variable features.\nIt returns a Seurat object with a new assay (sketch), consisting of ncells bins selected based off a “leverage score” for each bin. This step may take a few minutes to run.\n\n# we select 10,000 cells and create a new 'sketch' assay\nseurat_sketch &lt;- SketchData(object = seurat_sketch,\n                            assay = 'Spatial.008um',\n                            ncells = 10000,\n                            method = \"LeverageScore\",\n                            sketched.assay = \"sketch\")"
  },
  {
    "objectID": "lessons/05_normalization_and_sketch_downsampling.html#sketch-assay",
    "href": "lessons/05_normalization_and_sketch_downsampling.html#sketch-assay",
    "title": "Normalization and Sketch Downsampling",
    "section": "Sketch Assay",
    "text": "Sketch Assay\nWe can see that there are four major changes that have taken place:\n\nThe number of features in the second line has double, because we have added a new assay\nAccordingly, the number of assays has increased from one to two\nThe active assay has change from Spatial.016um to sketch\nThere is a new line listing additional assays that exist in the Seurat object\n\n\nseurat_sketch\n\nAn object of class Seurat \n36170 features across 826613 samples within 2 assays \nActive assay: sketch (18085 features, 2000 variable features)\n 2 layers present: counts, data\n 1 other assay present: Spatial.008um\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nWe can also see that the leverage.score has been added as a column to the metadata of our object.\n\nseurat_sketch@meta.data %&gt;% View()"
  },
  {
    "objectID": "lessons/05_normalization_and_sketch_downsampling.html#visualizing-leverage-scores",
    "href": "lessons/05_normalization_and_sketch_downsampling.html#visualizing-leverage-scores",
    "title": "Normalization and Sketch Downsampling",
    "section": "Visualizing Leverage Scores",
    "text": "Visualizing Leverage Scores\n\nggplot(seurat_sketch@meta.data) +\n  geom_histogram(aes(x=leverage.score, fill=orig.ident), \n                 alpha=0.5, bins=100) +\n  theme_classic() +\n  scale_x_log10(labels = scales::label_number())\n\n\n\n\n\n\n\n\n\nSpatialFeaturePlot(seurat_sketch,\n                   \"leverage.score\",\n                   pt.size.factor = 3,\n                   image.alpha = 0,\n                   max.cutoff = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3"
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html",
    "href": "lessons/06_scRNAseq_workflow.html",
    "title": "Identifying Unwanted Variation",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#identify-highly-variable-features",
    "href": "lessons/06_scRNAseq_workflow.html#identify-highly-variable-features",
    "title": "Identifying Unwanted Variation",
    "section": "Identify Highly Variable Features",
    "text": "Identify Highly Variable Features\nRecall that when we were working with the entire dataset, we found the following genes to be the most variable:\n\n# Identify the 15 most highly variable genes\nranked_variable_genes &lt;- VariableFeatures(seurat_sketch, assay=\"Spatial.008um\")\ntop_genes &lt;- ranked_variable_genes[1:15]\ntop_genes\n\n [1] \"IGHG3\" \"IGHM\"  \"SPP1\"  \"IGLC7\" \"IGLC1\" \"SST\"   \"IGHG1\" \"INSL5\" \"CHGA\" \n[10] \"VIP\"   \"HBA2\"  \"GCG\"   \"CXCL8\" \"MMP12\" \"PYY\"  \n\n\nWe are going to run FindVariableFeatures() once more, but this time on our smaller dataset of 10,000 bins.\n\n# Identify the most variable genes\nseurat_processed &lt;- FindVariableFeatures(seurat_sketch, \n                                         selection.method = \"vst\",\n                                         nfeatures = 2000,\n                                         assay=\"sketch\")\nseurat_processed\n\nAn object of class Seurat \n36170 features across 826613 samples within 2 assays \nActive assay: sketch (18085 features, 2000 variable features)\n 2 layers present: counts, data\n 1 other assay present: Spatial.008um\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\nDo you seen any differences when we calculated HVGs for the entire dataset versus the sketch assay?\n\n# Identify the 15 most highly variable genes\nranked_variable_genes &lt;- VariableFeatures(seurat_processed, assay=\"sketch\")\nranked_variable_genes[1:15]\n\n [1] \"IGHM\"  \"IGHG1\" \"IGLC1\" \"CHGA\"  \"VIP\"   \"CXCL8\" \"SPP1\"  \"GCG\"   \"IGHG3\"\n[10] \"IGHA1\" \"PYY\"   \"REG3A\" \"HBA2\"  \"INSL5\" \"ODAM\"",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#visualize-highly-variable-genes",
    "href": "lessons/06_scRNAseq_workflow.html#visualize-highly-variable-genes",
    "title": "Identifying Unwanted Variation",
    "section": "Visualize Highly Variable Genes",
    "text": "Visualize Highly Variable Genes\nWe can visualize the dispersion of all genes using Seurat’s VariableFeaturePlot(), which shows a gene’s average expression across all cells on the x-axis and variance on the y-axis. Ideally we would see genes lay across the entire x-axis, as we want to ensure that we are using genes that are both lowly and highly expressed.\nFor the visualization, we are adding labels using LabelPoints() to help us better understand which genes are driving the shape of our data.\n\n# Identify the 15 most highly variable genes\nranked_variable_genes &lt;- VariableFeatures(seurat_processed,\n                                          assay = \"sketch\")\ntop_genes &lt;- ranked_variable_genes[1:15]\n\n# Plot the average expression and variance of these genes\n# With labels to indicate which genes are in the top 15\np &lt;- VariableFeaturePlot(seurat_processed)\nLabelPoints(plot = p, points = top_genes, repel = TRUE)\n\n\n\n\n\n\n\n\nNow we are primed to run the next step of the workflow, which is Principal Component Analysis.",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#pca",
    "href": "lessons/06_scRNAseq_workflow.html#pca",
    "title": "Identifying Unwanted Variation",
    "section": "PCA",
    "text": "PCA\nPrincipal Component Analysis (PCA) is a technique used to emphasize variation as well as similarity, and to bring out strong patterns in a dataset; it is one of the methods used for “dimensionality reduction”.\n\n\n\n\n\n\nVideo on how PCA is calculated\n\n\n\n\n\nFor a more detailed explanation on PCA, please look over this lesson (adapted from StatQuests/Josh Starmer’s YouTube video). We also strongly encourage you to explore the video StatQuest’s video for a more thorough understanding.\n\n\n\nLet’s say you are working with a single-cell RNA-seq dataset with 12,000 cells and you have quantified the expression of 20,000 genes. The schematic below demonstrates how you would go from a cell x gene matrix to principal component (PC) scores for each individual cell.\n\nTo perform PCA, we need to first choose the most variable features, then scale the data. Since highly expressed genes exhibit the highest amount of variation and we don’t want our ‘highly variable genes’ only to reflect high expression, we need to scale the data to scale variation with expression level. The Seurat ScaleData() function will scale the data by:\n\nAdjusting the expression of each gene to give a mean expression across cells to be 0\nScaling expression of each gene to give a variance across cells to be 1\n\n\n# Scale the data counts\nseurat_processed &lt;- ScaleData(seurat_processed)\nseurat_processed\n\nAn object of class Seurat \n36170 features across 826613 samples within 2 assays \nActive assay: sketch (18085 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: Spatial.008um\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nWe have calculated a new layer titled sale.data, where our scaled log-normalized counts now exist. So now we can proceed in calculating our Principal Components with RunPCA().\n\n# Run PCA\nseurat_processed &lt;- RunPCA(seurat_processed,\n                           assay = \"sketch\",\n                           reduction.name = \"pca.sketch\")\n\nThe information printed out show the top genes that influence a cell’s score for each component. This includes genes that have both a positive and negative weight.\nIf we look at our updated seurat_processed object:\n\nseurat_processed\n\nAn object of class Seurat \n36170 features across 826613 samples within 2 assays \nActive assay: sketch (18085 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: Spatial.008um\n 1 dimensional reduction calculated: pca.sketch\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nWe see that we have stored our PCA results: dimensional reduction calculated: pca.sketch",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#visualize-pca",
    "href": "lessons/06_scRNAseq_workflow.html#visualize-pca",
    "title": "Identifying Unwanted Variation",
    "section": "Visualize PCA",
    "text": "Visualize PCA\nAfter the PC scores have been calculated, you are looking at a matrix of 12,000 x 12,000 that represents the information about relative gene expression in all the cells. You can select the PC1 and PC2 columns and plot that in a 2D way.\n\n\nDimPlot(seurat_processed,\n        reduction = \"pca.sketch\")\n\n\n\n\n\n\n\n\nUltimately what we have calculated with PCA are values that can represent how similar cells are to one another. We would expect that cells with similar gene expression will have similar PC values. For example, we would anticipate that two Fibroblast cells would have comparable gene expression - which would also results in similar scores in principal components. This is why many of the downstream steps in the remainder of this lesson use PCA as the input.",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#selecting-pc-dimensions",
    "href": "lessons/06_scRNAseq_workflow.html#selecting-pc-dimensions",
    "title": "Identifying Unwanted Variation",
    "section": "Selecting PC Dimensions",
    "text": "Selecting PC Dimensions\nTo overcome the extensive technical noise in the expression of any single gene for scRNA-seq data, Seurat assigns cells to clusters based on their PCA scores derived from the expression of the integrated most variable genes. Each PC essentially representing a “metagene” that combines information across a correlated gene set. Determining how many PCs to include in the clustering step is therefore important to ensure that we are capturing the majority of the variation, or cell types, present in our dataset.\nIt is useful to explore the PCs prior to deciding which PCs to include for the downstream clustering analysis.\nThe elbow plot is a helpful way to determine how many PCs to use for clustering so that we are capturing majority of the variation in the data. The elbow plot visualizes the standard deviation of each PC, and we are looking for where the standard deviations begins to plateau. Essentially, where the elbow appears is usually the threshold for identifying the majority of the variation. However, this method can be quite subjective.\nLet’s draw an elbow plot using the top 50 PCs:\n\n# Plot the elbow plot\nElbowPlot(object = seurat_processed,\n          reduction = \"pca.sketch\",\n          ndims = 50)\n\n\n\n\n\n\n\n\nBased on this plot, we could roughly determine the majority of the variation by where the elbow occurs around PC8 - PC10, or one could argue that it should be when the data points start to get close to the X-axis, PC30 or so. This gives us a very rough idea of the number of PCs needed to be included.\nWe will be using 50 PCs for our downstream steps.",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#k-nearest-neighbors",
    "href": "lessons/06_scRNAseq_workflow.html#k-nearest-neighbors",
    "title": "Identifying Unwanted Variation",
    "section": "k-Nearest Neighbors",
    "text": "k-Nearest Neighbors\nThe first step is to construct a K-nearest neighbor (KNN) graph based on the euclidean distance in PCA space.\n Image source: Analysis of Single cell RNA-seq data\n\nEdges are drawn between cells with similar features expression patterns.\nEdge weights are refined between any two cells based on shared overlap in their local neighborhoods.\n\nThis is done in Seurat by using the FindNeighbors() function. We also specify the reduction we want to use as well as which components (dims) will be used for the calculation. In this case, we will be using the first 50.\n\n# Determine the K-nearest neighbor graph\nseurat_processed &lt;- FindNeighbors(seurat_processed, \n                                  assay = \"sketch\", \n                                  reduction = \"pca.sketch\",\n                                  dims = 1:50)",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#clustering",
    "href": "lessons/06_scRNAseq_workflow.html#clustering",
    "title": "Identifying Unwanted Variation",
    "section": "Clustering",
    "text": "Clustering\nNext, Seurat will iteratively group cells together with the goal of optimizing the standard modularity function.\nWe will use the FindClusters() function to perform the graph-based clustering. The resolution is an important argument that sets the “granularity” of the downstream clustering and will need to be optimized for every individual experiment. For datasets of 3,000 - 5,000 cells, the resolution set between 0.4-1.4 generally yields good clustering. Increased resolution values lead to a greater number of clusters, which is often required for larger datasets.\nThe FindClusters() function allows us to enter a series of resolutions and will calculate the “granularity” of the clustering. This is very helpful for testing which resolution works for moving forward without having to run the function for each resolution.\n\n\n\n\n\n\nTesting different resolution values\n\n\n\nTypically we would recommend using a variety of different resolutions and select a resolution that best suits your dataset. However, for the sake of time, we will proceed with a resolution = 0.65. We have more detailed explanations of how to test a variety of resolutions at one time.\n\n\n\nseurat_processed &lt;- FindClusters(seurat_processed, \n                                 cluster.name = \"seurat_cluster.sketched\", \n                                 resolution = 0.65)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 10000\nNumber of edges: 478594\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8783\nNumber of communities: 17\nElapsed time: 1 seconds\n\n\nIf we take a look at the columns in our @meta.data, we see that the column seurat_cluster.sketched is a new column that was added.\n\nseurat_processed@meta.data %&gt;% head() %&gt;% relocate(\"seurat_cluster.sketched\")\n\n                            seurat_cluster.sketched orig.ident\nP5CRC_s_008um_00602_00290-1                    &lt;NA&gt;      P5CRC\nP5CRC_s_008um_00789_00234-1                    &lt;NA&gt;      P5CRC\nP5CRC_s_008um_00728_00006-1                    &lt;NA&gt;      P5CRC\nP5CRC_s_008um_00681_00396-1                    &lt;NA&gt;      P5CRC\nP5CRC_s_008um_00078_00444-1                    &lt;NA&gt;      P5CRC\nP5CRC_s_008um_00128_00278-1                    &lt;NA&gt;      P5CRC\n                            nCount_Spatial.008um nFeature_Spatial.008um\nP5CRC_s_008um_00602_00290-1                  225                    199\nP5CRC_s_008um_00789_00234-1                   76                     71\nP5CRC_s_008um_00728_00006-1                  215                    196\nP5CRC_s_008um_00681_00396-1                   74                     71\nP5CRC_s_008um_00078_00444-1                   65                     57\nP5CRC_s_008um_00128_00278-1                 1300                    906\n                            log10GenesPerUMI  mitoRatio leverage.score\nP5CRC_s_008um_00602_00290-1        0.9773277 0.04888889     0.09142904\nP5CRC_s_008um_00789_00234-1        0.9842859 0.01315789     0.01895360\nP5CRC_s_008um_00728_00006-1        0.9827724 0.04651163     0.20933028\nP5CRC_s_008um_00681_00396-1        0.9903846 0.04054054     0.06665954\nP5CRC_s_008um_00078_00444-1        0.9685377 0.23076923     0.02559120\nP5CRC_s_008um_00128_00278-1        0.9496410 0.17307692     0.17665603\n                            seurat_clusters\nP5CRC_s_008um_00602_00290-1            &lt;NA&gt;\nP5CRC_s_008um_00789_00234-1            &lt;NA&gt;\nP5CRC_s_008um_00728_00006-1            &lt;NA&gt;\nP5CRC_s_008um_00681_00396-1            &lt;NA&gt;\nP5CRC_s_008um_00078_00444-1            &lt;NA&gt;\nP5CRC_s_008um_00128_00278-1            &lt;NA&gt;\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nWhen we looked at the first few rows of our metadata, it appeared that there were many cells that do not have a cluster value.\nCount how many NA’s are found for our cluster with table() function and use the argument (useNA = \"ifany\"):\n\ntable(seurat_processed$seurat_cluster.sketched, useNA = \"ifany\")\n\n\n     0      1      2      3      4      5      6      7      8      9     10 \n  1656   1330   1021   1006    994    795    609    557    556    458    333 \n    11     12     13     14     15     16   &lt;NA&gt; \n   189    167     99     93     77     60 816613 \n\n\nWhy do you think there are so many NA values?\n\n\nFindClusters() tends to automatically change the Idents() to the cluster values that were just calculated. If we take a look at our Idents we can see if that it has changed from orig.ident to seurat_cluster.sketched\n\nIdents(seurat_processed) %&gt;% head()\n\nP5CRC_s_008um_00602_00290-1 P5CRC_s_008um_00789_00234-1 \n                       &lt;NA&gt;                        &lt;NA&gt; \nP5CRC_s_008um_00728_00006-1 P5CRC_s_008um_00681_00396-1 \n                       &lt;NA&gt;                        &lt;NA&gt; \nP5CRC_s_008um_00078_00444-1 P5CRC_s_008um_00128_00278-1 \n                       &lt;NA&gt;                        &lt;NA&gt; \nLevels: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#umap",
    "href": "lessons/06_scRNAseq_workflow.html#umap",
    "title": "Identifying Unwanted Variation",
    "section": "UMAP",
    "text": "UMAP\nTo visualize the cell clusters, there are a few different dimensionality reduction techniques that can be helpful. The most popular methods include t-distributed stochastic neighbor embedding (t-SNE) and Uniform Manifold Approximation and Projection (UMAP) techniques.\nBoth methods aim to place cells with similar local neighborhoods in high-dimensional space together in low-dimensional space. These methods will require you to input number of PCA dimentions to use for the visualization, we suggest using the same number of PCs as input to the clustering analysis. Here, we will proceed with the UMAP method for visualizing the clusters.\n\nseurat_processed &lt;- RunUMAP(seurat_processed, \n                            reduction = \"pca.sketch\", \n                            reduction.name = \"umap.sketch\", \n                            return.model = T, dims = 1:50)\nseurat_processed\n\nAn object of class Seurat \n36170 features across 826613 samples within 2 assays \nActive assay: sketch (18085 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: Spatial.008um\n 2 dimensional reductions calculated: pca.sketch, umap.sketch\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\n\nDimPlot(seurat_processed, group.by=\"orig.ident\", reduction=\"umap.sketch\")\n\n\n\n\n\n\n\n\nThese UMAP coordinates are now stored in the dimensional reductions calculated: pca.sketch, umap.sketch. Now we can visualize with the clusters that we calculated earlier using DimPlot() and adding clearer labels withLabelClusters()`.\n\n# Plot UMAP\np &lt;- DimPlot(seurat_processed, \n        reduction = \"umap.sketch\", label = T) + \n  ggtitle(\"Sketched clustering\")\nLabelClusters(p, id = \"ident\",  fontface = \"bold\", size = 5, \n              bg.colour = \"white\", bg.r = .2, force = 0)",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#run-projectdata",
    "href": "lessons/06_scRNAseq_workflow.html#run-projectdata",
    "title": "Identifying Unwanted Variation",
    "section": "Run ProjectData()",
    "text": "Run ProjectData()\nThe ProjectData function projects all the bins in the dataset (the Spatial.008um assay) onto the sketch assay.\n\n# Increases the size of the default vector\noptions(future.globals.maxSize= 2000000000)\n\nseurat_processed &lt;- ProjectData(\n  object = seurat_processed,\n  assay = \"Spatial.008um\",\n  full.reduction = \"full.pca.sketch\",\n  sketched.assay = \"sketch\",\n  sketched.reduction = \"pca.sketch\",\n  umap.model = \"umap.sketch\",\n  dims = 1:50,\n  refdata = list(seurat_cluster.projected = \"seurat_cluster.sketched\"))\n\nUsing the sketch PCA and UMAP, the ProjectData function returns a Seurat object that includes:\n\n\n\n\n\n\n\nCategory\nDescription\n\n\n\n\nDimensional reduction (PCA)\nThe full.pca.sketch reduction extends the PCA from sketched cells to all bins in the dataset\n\n\nDimensional reduction (UMAP)\nThe full.umap.sketch reduction extends the UMAP from sketched cells to all bins in the dataset\n\n\nCluster labels\nThe seurat_cluster.projected metadata column labels all cells with cluster labels from sketched cells\n\n\n\nWe can now see the additional full-dataset reductions in the object.\n\nseurat_processed\n\nAn object of class Seurat \n36170 features across 826613 samples within 2 assays \nActive assay: Spatial.008um (18085 features, 2000 variable features)\n 2 layers present: counts, data\n 1 other assay present: sketch\n 4 dimensional reductions calculated: pca.sketch, umap.sketch, full.pca.sketch, full.umap.sketch\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nNote that a score for the projection of each bin will be saved as a column in the metadata. Now the seurat_cluster.projected column shows values for every bin.\n\nhead(seurat_processed@meta.data)\n\n                            orig.ident nCount_Spatial.008um\nP5CRC_s_008um_00602_00290-1      P5CRC                  225\nP5CRC_s_008um_00789_00234-1      P5CRC                   76\nP5CRC_s_008um_00728_00006-1      P5CRC                  215\nP5CRC_s_008um_00681_00396-1      P5CRC                   74\nP5CRC_s_008um_00078_00444-1      P5CRC                   65\nP5CRC_s_008um_00128_00278-1      P5CRC                 1300\n                            nFeature_Spatial.008um log10GenesPerUMI  mitoRatio\nP5CRC_s_008um_00602_00290-1                    199        0.9773277 0.04888889\nP5CRC_s_008um_00789_00234-1                     71        0.9842859 0.01315789\nP5CRC_s_008um_00728_00006-1                    196        0.9827724 0.04651163\nP5CRC_s_008um_00681_00396-1                     71        0.9903846 0.04054054\nP5CRC_s_008um_00078_00444-1                     57        0.9685377 0.23076923\nP5CRC_s_008um_00128_00278-1                    906        0.9496410 0.17307692\n                            leverage.score seurat_cluster.sketched\nP5CRC_s_008um_00602_00290-1     0.09142904                    &lt;NA&gt;\nP5CRC_s_008um_00789_00234-1     0.01895360                    &lt;NA&gt;\nP5CRC_s_008um_00728_00006-1     0.20933028                    &lt;NA&gt;\nP5CRC_s_008um_00681_00396-1     0.06665954                    &lt;NA&gt;\nP5CRC_s_008um_00078_00444-1     0.02559120                    &lt;NA&gt;\nP5CRC_s_008um_00128_00278-1     0.17665603                    &lt;NA&gt;\n                            seurat_clusters seurat_cluster.projected\nP5CRC_s_008um_00602_00290-1            &lt;NA&gt;                        3\nP5CRC_s_008um_00789_00234-1            &lt;NA&gt;                        2\nP5CRC_s_008um_00728_00006-1            &lt;NA&gt;                        2\nP5CRC_s_008um_00681_00396-1            &lt;NA&gt;                        3\nP5CRC_s_008um_00078_00444-1            &lt;NA&gt;                        0\nP5CRC_s_008um_00128_00278-1            &lt;NA&gt;                        1\n                            seurat_cluster.projected.score\nP5CRC_s_008um_00602_00290-1                      1.0000000\nP5CRC_s_008um_00789_00234-1                      0.9325007\nP5CRC_s_008um_00728_00006-1                      0.9965810\nP5CRC_s_008um_00681_00396-1                      1.0000000\nP5CRC_s_008um_00078_00444-1                      0.6967176\nP5CRC_s_008um_00128_00278-1                      1.0000000",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow.html#visualize-projected-clusters",
    "href": "lessons/06_scRNAseq_workflow.html#visualize-projected-clusters",
    "title": "Identifying Unwanted Variation",
    "section": "Visualize Projected Clusters",
    "text": "Visualize Projected Clusters\nWe can now visualize our clusters from the projected assignments. The UMAP plot now contains more points, which is expected because we are now visualizing the full dataset rather than our 10,000 bin sketch. Nonetheless, we can see that the full dataset is still well-represented by the projected dimensional reduction and clustering.\n\n# switch to full dataset assay\nDefaultAssay(seurat_processed) &lt;- \"Spatial.008um\"\n\n# Change the idents to the projected cluster assignments\nIdents(seurat_processed) &lt;- \"seurat_cluster.projected\"\n\n# Plot UMAP\np &lt;- DimPlot(seurat_processed, \n        reduction = \"full.umap.sketch\", label = T) + \n  ggtitle(\"Projected clustering\")\nLabelClusters(p, id = \"ident\",  fontface = \"bold\", size = 5, \n              bg.colour = \"white\", bg.r = .2, force = 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy cluster labels are all out of order!\n\n\n\nTo ensure that our cluster labels are listed in proper numeric order, we are going to make our seurat_cluster.projected a factor and set the levels such that the order is correct.\n\n# Arrange so clusters get listed in numerical order\nseurat_processed$seurat_cluster.projected &lt;- seurat_processed$seurat_cluster.projected %&gt;% \n  as.numeric() %&gt;%\n  as.factor()\n\nseurat_processed$seurat_cluster.projected %&gt;% head()\n\nP5CRC_s_008um_00602_00290-1 P5CRC_s_008um_00789_00234-1 \n                         12                           2 \nP5CRC_s_008um_00728_00006-1 P5CRC_s_008um_00681_00396-1 \n                          2                          12 \nP5CRC_s_008um_00078_00444-1 P5CRC_s_008um_00128_00278-1 \n                         14                          15 \nLevels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17\n\n\nNow we should see the levels in correct numeric order.\n\n# Change the idents to the projected cluster assignments\nIdents(seurat_processed) &lt;- \"seurat_cluster.projected\"\n\n# Plot UMAP\np &lt;- DimPlot(seurat_processed, \n        reduction = \"full.umap.sketch\", label = T) + \n  ggtitle(\"Projected clustering\")\nLabelClusters(p, id = \"ident\",  fontface = \"bold\", size = 5, \n              bg.colour = \"white\", bg.r = .2, force = 0)\n\n\n\n\n\n\n\n\n\n\nIn order to see the clusters superimposed on our image we can use the SpatialDimPlot() function. We will also set the color palette and convert the cluster assignments to a factor so they are ordered numerically rather than lexicographically in the figure.\n\nSpatialDimPlot(seurat_processed,\n               pt.size.factor = 7,\n               image.alpha = 0)",
    "crumbs": [
      "Day 2:",
      "Identifying Unwanted Variation"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data.html",
    "href": "lessons/02_loading-spatial-data.html",
    "title": "Loading Spatial Data",
    "section": "",
    "text": "Approximate time: XY minutes",
    "crumbs": [
      "Day 1:",
      "Loading Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data.html#metadata",
    "href": "lessons/02_loading-spatial-data.html#metadata",
    "title": "Loading Spatial Data",
    "section": "Metadata",
    "text": "Metadata\n\nHuman CRCMouse Brain\n\n\nMatched control and cancerous colon sample from 58 year old female in stage IV-A.\n\nNatural (control)\nColorectal Cancer\n\nWith the associated paper\nWe expect to see the following celltypes in our dataset:\n\nB cells\nT cells\nTumor\nMyeloid\nFibroblast\nEndothelial\nIntestinal Epithelial\nSmooth Muscle\nNeuronal\n\n\n\nA mouse brain (fresh frozen) was obtained from Charles River Laboratories.\nStrain: C57BL/6 Sex: Male Age: 8 weeks Sample preparation\nA 10 µm section was taken with a cryostat (Epredia CryoStar NX70). Tissue block preparation, sectioning, H&E staining, and imaging followed the Visium HD Fresh Frozen Tissue Preparation Handbook (CG000763).\nThe data was subset to a smaller cross-section of the brain in order to make it more manageable on local laptops. The instructions for how to subset a 10X Visium HD slides can be found here.",
    "crumbs": [
      "Day 1:",
      "Loading Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data.html#downloading-the-r-project-and-data",
    "href": "lessons/02_loading-spatial-data.html#downloading-the-r-project-and-data",
    "title": "Loading Spatial Data",
    "section": "Downloading the R Project and Data",
    "text": "Downloading the R Project and Data\nWe have assembled an R Project for you to download that includes the data along with a basic file structure for maintain good data management. It can be quite easy when starting a new analysis to want to dive right in and start analyzing your data. However, good data management practices occur at each step of data’s lifecycle. It is a good habit to begin by creating a basic directory structure to hold your data. Let’s start by download this R Project and data from here. Left-click on the link and select Save Link As.. or Download Linked File As.., then select a place on your computer where you would like to place this R Project.\nWe can open the R Project up and see that the provided file structure should look like:\nIf your R Project looks like below, then you are ready to start!\nTODO: Insert picture of what the R Project will look when it is ready to start\n\n\n\n\n\n\nExercise 1\n\n\n\n\nGiven the information that we know from the metadata, what might be some questions that we want to answer using our data?\n\n\n\n\n# Creating Seurat object from SpaceRanger output\n# Visium HD spatial transcriptomics workshop\n# Author: Harvard Chan Bioinformatic Core\n# Created: December 2025\n\nlibrary(tidyverse)\nlibrary(Seurat)",
    "crumbs": [
      "Day 1:",
      "Loading Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data.html#data-files",
    "href": "lessons/02_loading-spatial-data.html#data-files",
    "title": "Loading Spatial Data",
    "section": "Data Files",
    "text": "Data Files\nTo load our data, we are going to make use of the function Load10X_Spatial(). The input needed for this function comes from the output generated by SpaceRanger, including both the feature matrix and low-resolution tissue image. Once supplied, a Seurat object that contains our counts matrix and image is created.\n\n\n\n\n\n\nUsing ? to look up function arguments\n\n\n\n\n\nIf you are ever unsure what parameters you can supply to a function, you make use of the ? call in R. This will bring up the manual page for the function while will provide more details on what each variable is used for.\n\n?Load10X_Spatial\n\n\n\n\nThere are 3 main arguments that we will be utilizing for this step:\n\n\n\nTable 1: Load10X_Spatial() arguments\n\n\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ndata.dir\nDirectory containing the H5 file specified by filename and the image data in a subdirectory called spatial\n\n\nbin.size\nSpecifies the bin sizes to read in (defaults to c(16, 8))\n\n\nslice\nName for the stored image of the tissue slice\n\n\n\n\n\n\nBefore loading in the data, let us take a look at the files we will supplying to the function. In particular, let us take a look at sample data/P5CRC which is the path would supply as data.dir in the Load10X_Spatial() function.\n\n\ndata/P5CRC/\n├── Visium_HD_Human_Colon_Cancer_P5_binned_outputs.tar.gz\n├── Visium_HD_Human_Colon_Cancer_P5_spatial.tar.gz\n├── binned_outputs\n│   ├── square_002um\n│   ├── square_008um\n│   └── square_016um\n└── spatial\n    ├── aligned_fiducials.jpg\n    ├── aligned_tissue_image.jpg\n    ├── cytassist_image.tiff\n    ├── detected_tissue_image.jpg\n    ├── tissue_hires_image.png\n    └── tissue_lowres_image.png\n\n\nIn the Visium HD assay, SpaceRanger bins the image into 2µm x 2µm, 8µm x 8µm, and 16µm x 16µm bins. The output from each of these resolution is found in the binned_outputs folder.\n\n\n\n\n\n\nChoosing your bin size\n\n\n\nThis is not an easy question to answer!\nThe typical recommendation for a Visium HD analysis is to use the 8µm x 8µm resolution of the dataset. However, it is important to consider the dataset you are working with. For example, neuron cells are know to be a larger celltype in size. Therefore it would be good to consider a large bin size in order to fully represent each cell within a bin.\nThere are numerous algorithms that have been created to identify the boundaries of cells to ensure that counts are being associated with single-cells. This process is typically referred to as segmentation, which we will cover in a later lesson.",
    "crumbs": [
      "Day 1:",
      "Loading Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data.html#creating-the-seurat-object",
    "href": "lessons/02_loading-spatial-data.html#creating-the-seurat-object",
    "title": "Loading Spatial Data",
    "section": "Creating the Seurat Object",
    "text": "Creating the Seurat Object\nNow that we understand the input needed for the Load10X_Spatial() function, let’s use it to create a Seurat object called crc. We will specify that we want to load in the 8µm and 16µm bin sizes at the same time.\nTypically you would only load in one bin size, but for the purposes of better understanding bins and our Seurat data structure, we will load both here.\n\ncrc &lt;- Load10X_Spatial(data.dir = \"data/P5CRC/\",\n                       bin.size = c(8, 16),\n                       slice = \"P5CRC\")\n\nWe can print out some basic information of our Seurat object to examine its data structure. We will do this frequently throughout the workshop to understand how our the Seurat data structure changes with each step of the workflow.\n\ncrc\n\nAn object of class Seurat \n36170 features across 678003 samples within 2 assays \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 1 other assay present: Spatial.016um\n 2 spatial fields of view present: P5CRC.008um P5CRC.016um",
    "crumbs": [
      "Day 1:",
      "Loading Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data.html#anatomy-of-a-seurat-object",
    "href": "lessons/02_loading-spatial-data.html#anatomy-of-a-seurat-object",
    "title": "Loading Spatial Data",
    "section": "Anatomy of a Seurat Object",
    "text": "Anatomy of a Seurat Object\nAs we can see from our Seurat callout, there are a lot of different slots inside our object. Here, we will go through each of the major components of a Seurat object and how you would access key pieces of information.\n\nAssays\nAssays are where we can store different counts matrices - we are not forced to keep the same features and variable genes across assays. Each assay will contain it’s own Layers that can be distinct from other assays in the object. This is useful in several different cases:\n\nMulti-modal assays, where you can keep the expression matrices for RNA, ATAC, or protein in a single Seurat object\nStoring counts matrices from a variety of different normalization techniques\nBatch integration methods will sometimes generate a transformed counts matrix\n\nHere we can print the different assays that exist within our crc object:\n\nAssays(crc)\n\n[1] \"Spatial.008um\" \"Spatial.016um\"\n\n\nWe have 2 distinct assays for the different bin sizes, which makes sense because we have different count matrices for our cells based upon the bin size that was selected.\nThe DefaultAssay() function shows us which assay information will be used in other Seurat function calls, unless explicitly specified otherwise.\n\nDefaultAssay(crc)\n\n[1] \"Spatial.008um\"\n\n\nWe can also change what our default assay is. Let’s set it to the 016um bins:\n\nDefaultAssay(crc) &lt;- \"Spatial.016um\"\ncrc\n\nAn object of class Seurat \n36170 features across 678003 samples within 2 assays \nActive assay: Spatial.016um (18085 features, 0 variable features)\n 1 layer present: counts\n 1 other assay present: Spatial.008um\n 2 spatial fields of view present: P5CRC.008um P5CRC.016um\n\n\nNow we see that the callout says: Active assay: Spatial.016um\n\n\nFeatures and Cells\nOur count matrices function as any other matrix does, with rows and columns.\nIn Seurat, the rows correspond to Features. In the case of spatial transcriptomics, our features are genes. In other experiments, features could refer to chromatin peaks or proteins. The important thing to keep in mind is what technology you are using. Since this is a Visium HD dataset, we are quantifying RNA expression (genes).\nWe can see what the first few genes/features in our count matrix are:\n\nFeatures(crc) %&gt;% head()\n\n[1] \"SAMD11\"  \"NOC2L\"   \"KLHL17\"  \"PLEKHN1\" \"PERM1\"   \"HES4\"   \n\n\nAs well as see the number of genes that are found in each of our assays:\n\nnrow(crc[[\"Spatial.008um\"]])\n\n[1] 18085\n\nnrow(crc[[\"Spatial.016um\"]])\n\n[1] 18085\n\n\nThe columns correspond to Cells (or samples as it appears in the callout). We can see what the first few cells in our count matrix are:\n\nCells(crc) %&gt;% head()\n\n[1] \"s_016um_00052_00082-1\" \"s_016um_00396_00063-1\" \"s_016um_00297_00147-1\"\n[4] \"s_016um_00347_00254-1\" \"s_016um_00299_00088-1\" \"s_016um_00050_00315-1\"\n\n\nAs well as see the number of cells that are found in each of our assays:\n\nncol(crc[[\"Spatial.008um\"]])\n\n[1] 541968\n\nncol(crc[[\"Spatial.016um\"]])\n\n[1] 136035\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\nWhat differences do you see between the 8um and 16um bins?\n\n\n\n\n\nLayers\nLayers are our count matrices.\n\nLayers(crc)\n\n[1] \"counts\"\n\n\nBy default, Seurat uses the following naming convention for the counts matrices within an Assay:\n\n\n\nTable 2: Description of each Layer() count matrix\n\n\n\n\n\nLayer\nDescription\n\n\n\n\ncounts\nRaw counts\n\n\ndata\nNormalized counts\n\n\nscale.data\nScaled‑normalized counts\n\n\n\n\n\n\nYou may notice that our Seurat object only contains counts right now. This is because we have not run any normalization steps yet (we will discuss how to do so in future lessons).\nUsing the LayerData() function we can access the entire counts matrix. Furthermore, we can specify the assay if we would prefer to not use the DefaultAssay.\n\nLayerData(crc, \n          assay = \"Spatial.016um\", \n          layer = \"count\")[1:5, 1:5]\n\n\n\n\n\nTable 3: First 5 rows and columns of raw counts matrix\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ns_016um_00052_00082-1\ns_016um_00396_00063-1\ns_016um_00297_00147-1\ns_016um_00347_00254-1\ns_016um_00299_00088-1\n\n\n\n\nSAMD11\n0\n0\n0\n0\n0\n\n\nNOC2L\n1\n1\n0\n0\n0\n\n\nKLHL17\n0\n0\n0\n0\n0\n\n\nPLEKHN1\n0\n0\n0\n0\n0\n\n\nPERM1\n0\n0\n0\n0\n0\n\n\n\n\n\n\n\n\nBy printing the first 5 features and cells in our object (for easier visualization). We can see that we are working with whole numbers which reinforces the idea that this is the raw data, with no transformations having been applied.\n\n\nSpatial Fields\nWe do not just have expression data associated with our sample, we also have the spatial slide that comes with its own set of values and information.\nFor example we can grab the x,y coordinates of each bin using the GetTissueCoordinates() function.\n\nGetTissueCoordinates(crc) %&gt;% View()\n\n\n\n\n\nTable 4: Coordinates on spatial slide for each cell\n\n\n\n\n\n\n\n\n\n\nOr visualize what our slide looks like with SpatialDimPlot():\n\nSpatialDimPlot(crc)\n\n\n\n\n\n\n\nFigure 1: Spatial visualization of spots with SpatialDimPlot()\n\n\n\n\n\n\n\nMetadata\nSeurat automatically creates some metadata for each of the cells when the object is created. This information is stored in the @meta.data slot within the Seurat object. The rownames are automatically set to be the cell names.\n\ncrc@meta.data %&gt;% View()\n\n\n\n\n\nTable 5: Seurat default @meta.data\n\n\n\n\n\n\n\n\n\n\nWhat does each column represent?\n\n\n\nTable 6: Columns automatically populated in @meta.data\n\n\n\n\n\nColumn\nDescription\n\n\n\n\norig.ident\nSample identity if known; defaults to “s”\n\n\nnCount_RNA\nNumber of UMIs per cell\n\n\nnFeature_RNA\nNumber of genes detected per cell\n\n\n\n\n\n\nWhile it may seem intimidating at first, the important thing to remember is that this is a dataframe. Therefore can modify and work with this dataframe just like we would any other in R! For example, we can set our orig.ident column to be our sample name rather than “s”.\n\ncrc@meta.data$orig.ident &lt;- \"P5CRC\"\n\n\ncrc@meta.data %&gt;% View()\n\n\n\n\n\nTable 7: Seurat default @meta.data after updating orig.ident\n\n\n\n\n\n\n\n\n\n\nAdditionally, we do not have use the @meta.data each time we want to access a single column. We can use the $ follow by the column name as a shorthand.\n\ncrc$nCount_Spatial.008um %&gt;% head()\n\ns_008um_00602_00290-1 s_008um_00789_00234-1 s_008um_00728_00006-1 \n                  225                    76                   215 \ns_008um_00526_00291-1 s_008um_00681_00396-1 s_008um_00078_00444-1 \n                   57                    74                    65 \n\n\n\n\nIdents\nThe cell identities are stored as Idents(), which contain the default way to label cells. For example, if we wanted to label each cell by which sample they came from we could run:\n\nIdents(crc) &lt;- \"orig.ident\"\nIdents(crc) %&gt;% head()\n\ns_008um_00602_00290-1 s_008um_00789_00234-1 s_008um_00728_00006-1 \n                P5CRC                 P5CRC                 P5CRC \ns_008um_00526_00291-1 s_008um_00681_00396-1 s_008um_00078_00444-1 \n                P5CRC                 P5CRC                 P5CRC \nLevels: P5CRC\n\n\nWhere we see that the identities of the cells are the value stored in the @meta.data column orig.ident.",
    "crumbs": [
      "Day 1:",
      "Loading Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data.html#using-a-for-loop",
    "href": "lessons/02_loading-spatial-data.html#using-a-for-loop",
    "title": "Loading Spatial Data",
    "section": "Using a for Loop",
    "text": "Using a for Loop\nIn practice, you will likely have several samples that you will need to read in data for, and that can get tedious and error-prone if you do it one at a time. So, to make the data import into R more efficient we can use a for loop, which will iterate over a series of commands for each of the inputs given and create Seurat objects for each of our samples.\n\n\n\n\n\n\nfor loop syntax\n\n\n\n\n\nIn R, the for loop has the following structure/syntax:\n\n## DO NOT RUN\n\nfor (variable in input){\n    command1\n    command2\n    command3\n}\n\n\n\n\nToday we will use it to iterate over the two sample folders and execute commands for each sample as we did above for a single sample:\n\nCreate the Seurat objects from the SpaceRanger data (Load10X_Spatial()) and specify slice so that images are labeled with their sample name\nSet orig.ident to be our sample\n\nOnce those steps run, we will store the newly generated Seurat object to a list called list_seurat so that we can eventually merge both samples together.\nWe will be using a bin size of 8um for the remainder of this workshop\n\nsamples &lt;- c(\"P5CRC\", \"P5NAT\")\nlist_seurat &lt;- list()\n\nfor (sample in samples) {\n  \n  # Path to data directory\n  data_dir &lt;- paste0(\"data/\", sample)\n  # Create seurat object and set orig ident to be sample\n  seurat &lt;- Load10X_Spatial(data.dir = data_dir,\n                            bin.size = c(8),\n                            slice = sample)\n  seurat$orig.ident &lt;- sample\n  \n  # Store seurat object in our list\n  list_seurat[[sample]] &lt;- seurat\n}\n\nTo confirm that we succesfully loaded both samples in, we can take a look at the contents of list_seurat. We should see that there are two Seurat objects in our list that correspond to each sample.\n\nlist_seurat\n\n$P5CRC\nAn object of class Seurat \n18085 features across 541968 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 1 spatial field of view present: P5CRC.008um\n\n$P5NAT\nAn object of class Seurat \n18085 features across 435773 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 1 spatial field of view present: P5NAT.008um\n\n\nThis is exactly what we had hoped to see! So now we can move on to the next step which is merging the sample together into a singular Seurat object.\n\n\n\n\n\n\nWhat if I am merging more than two samples?\n\n\n\n\n\nSeurat has functionality to merge many samples together. You can do this quite easily by adding all sample objects to the y argument in a vector format. An example is provided below, assuming you use the list structured we used previously:\n\n## DO NOT RUN\nmerged_seurat &lt;- merge(x = seurat_list[[1]], \n                       y = seurat_list[[2:length(seurat_list)]],\n                       add.cell.id = names(seurat_list))",
    "crumbs": [
      "Day 1:",
      "Loading Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data.html#merge-datasets-together",
    "href": "lessons/02_loading-spatial-data.html#merge-datasets-together",
    "title": "Loading Spatial Data",
    "section": "Merge Datasets Together",
    "text": "Merge Datasets Together\nWe merge samples together because it make it easier to run the QC steps for both sample groups together. It also enables us to easily compare the data quality for all cells at one time\nTo create this combined Seurat object, we use the merge() function. Because the same cell IDs can be used for different samples, we add a sample-specific prefix to each of our cell IDs using the add.cell.id argument to ensure the cell names are unique.\n\nseurat_merged &lt;- merge(x = list_seurat[[\"P5CRC\"]],\n                       y = list_seurat[[\"P5NAT\"]],\n                       add.cell.id = c(\"P5CRC\", \"P5NAT\"))\nseurat_merged\n\nAn object of class Seurat \n18085 features across 977741 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 2 layers present: counts.1, counts.2\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nFrom the callout we can see that we now have: 2 layers present: counts.1, counts.2\nHowever, we do not want to have two distinct raw counts matrices (counts.1 and counts.2). We want the counts for each sample to be concatenated together. This would be a single, large count matrix that represent each cell in the dataset. Seurat’s function JoinLayers() allows us to do just this.\n\nseurat_merged &lt;- JoinLayers(seurat_merged)\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nWhat function can we use to double check that we have a singular counts layer?\n\n\n\n\n\n\n\n\n\nMerging vs. Integration\n\n\n\n\n\nA common point of confusion is the distinction between integration and merging. In the field, integration is considered to be modifying either your counts or latent space in a way to correct for a batch variable. Whereas what we are doing now is merging or concatenating multiple samples together. This process of merging does not transform the values in the count matrices.",
    "crumbs": [
      "Day 1:",
      "Loading Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data.html#evaluating-merged_seurat",
    "href": "lessons/02_loading-spatial-data.html#evaluating-merged_seurat",
    "title": "Loading Spatial Data",
    "section": "Evaluating merged_seurat",
    "text": "Evaluating merged_seurat\nLet’s also double check that we have the correct number of cells. First, let us see what the number of cells was for each sample:\n\nncol(list_seurat[[\"P5CRC\"]]) + ncol(list_seurat[[\"P5NAT\"]])\n\n[1] 977741\n\n\nWhich is the same as the number of samples in our Seurat callout!\n\nseurat_merged\n\nAn object of class Seurat \n18085 features across 977741 samples within 1 assay \nActive assay: Spatial.008um (18085 features, 0 variable features)\n 1 layer present: counts\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um\n\n\nIf we look at the metadata of the merged object we should be able to see the prefixes in the rownames (Cells) as well as the updated orig.ident we set in the for loop earlier.\n\n# Check that the merged object has the appropriate sample-specific prefixes\nseurat_merged@meta.data %&gt;% head()\n\n\n\n\n\nTable 8: First 5 rows of @meta.data\n\n\n\n\n\n\n\n\n\n\n\nseurat_merged@meta.data %&gt;% tail()\n\n\n\n\n\nTable 9: Last 5 rows of @meta.data\n\n\n\n\n\n\n\n\n\n\nLastly we want to make sure that the Idents of our cells is a useful piece of information, for example like orig.ident, which contains our sample IDs.\n\nIdents(seurat_merged) &lt;- \"orig.ident\"",
    "crumbs": [
      "Day 1:",
      "Loading Spatial Data"
    ]
  },
  {
    "objectID": "lessons/02_loading-spatial-data_Answer-key.html",
    "href": "lessons/02_loading-spatial-data_Answer-key.html",
    "title": "Loading Spatial Data Answer Key",
    "section": "",
    "text": "Exercise 1\n1. Given the information that we know from the metadata, what might be some questions that we are interested in interrogating using our data?\n\nIdentify and characterize tumor cells in CRC\nConstruct cell-communication networks, using spatial locations to constrain our results\nWhat are unique subtypes/cell states that are found in CRC vs. NAT\nAssociate cell states with spatial locations\nEstablish domains and niches of cell populations in quadrants of the slides\netc.\n\n\n\nExercise 2\n2. What differences do you see between 8um and 16um bins?\nThere are more cells in the 8um compared to the 16um. The number of features/genes remain the same.\nThis is why the bin value matters, it determines how many “cells” are ultimately generated. A smaller bin size results in more spots. This is because we are taking smaller sections of the same data, meaning we use more bins to cover the same area as a large bin size.\n\n\nExercise 3\n3. What function can we use to double check that we have a singular counts layer?\n\nLayers(seurat_merged)"
  },
  {
    "objectID": "lessons/05_normalization_and_sketch_downsampling_Answer-key.html",
    "href": "lessons/05_normalization_and_sketch_downsampling_Answer-key.html",
    "title": "Normalization and Regressing Out Unwanted Variation Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/06_scRNAseq_workflow_Answer-key.html",
    "href": "lessons/06_scRNAseq_workflow_Answer-key.html",
    "title": "Clustering Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/07_integration.html",
    "href": "lessons/07_integration.html",
    "title": "Integration",
    "section": "",
    "text": "Approximate time: XY minutes"
  },
  {
    "objectID": "lessons/07_integration.html#batch-distribution-in-clusters",
    "href": "lessons/07_integration.html#batch-distribution-in-clusters",
    "title": "Integration",
    "section": "Batch Distribution in Clusters",
    "text": "Batch Distribution in Clusters\nWe do see a clear split in our dataset between our NAT and CRC samples. This is emphasized even more when we look at the distribution of cells in each cluster.\n\n# Barplot of proportion of cells in each cluster by sample\nggplot(seurat_processed@meta.data) +\n    geom_bar(aes(x=seurat_cluster.projected, fill=orig.ident), \n             position=position_fill())  +\n    theme_classic()\n\n\n\n\n\n\n\n\nIn particular, this tells us that we need to zoom in on clusters 1 and 10 to determine if integration is necessary."
  },
  {
    "objectID": "lessons/07_integration.html#possible-explanations",
    "href": "lessons/07_integration.html#possible-explanations",
    "title": "Integration",
    "section": "Possible Explanations",
    "text": "Possible Explanations\nAt such a low resolution, we expect our clusters to map to larger celltypes. Therefore, before running any single-cell analysis, it is important to come in with some expectations of your cell population. Even better would be to make use of known marker genes curated from previous publications. Here, we have provided a few examples of genes that we would expect to represent some of the cell populations.\n\n\n\n\n\n\n\nCell type\nGenes\n\n\n\n\nGoblet cells\nCLCA1, FCGBP, MUC2\n\n\nGoblet/Entero\nPIGR\n\n\nTumor\nCEACAM6, CEACAM5\n\n\nFibroblasts\nCOL1A1\n\n\nMacrophages\nC1QC, SPP1, SELENOP\n\n\nCAF\nCOL1A1\n\n\nT cells\nTRAC, CD3E\n\n\nEndothelial\nPECAM1\n\n\nPlasma cells\nIGKC\n\n\n\nIt is tempting to jump straight into integration! However, it is best to give a justification why such a step is necessary to unsure that you are not losing real biology in the process of doing so.\n\n\n\n\n\n\nExercise 2\n\n\n\nIs there a population here that could potentially explain the differences between our samples?"
  },
  {
    "objectID": "lessons/07_integration.html#assessing-tumor-cells",
    "href": "lessons/07_integration.html#assessing-tumor-cells",
    "title": "Integration",
    "section": "Assessing Tumor Cells",
    "text": "Assessing Tumor Cells\nSince we are comparing cancerous versus normal samples, it would make sense that our P5CRC sample will have a unique population of tumor cells. In CRC, CEACAM6 and CEACAM5 are good marker genes for identifying tumor cells.\nAccording to genecards, CEACAM6 is also known as “Carcinoembryonic Antigen-Related Cell Adhesion Molecule 6” where:\n\nMembers of this family play a role in cell adhesion and are widely used as tumor markers in serum immunoassay determinations of carcinoma. This gene affects the sensitivity of tumor cells to adenovirus infection.\n\nTo see if these genes are associated with the clusters we identified previously, we can utilize VlnPlot() to identify clusters with higher expression of these tumor genes.\n\nVlnPlot(seurat_processed, \"CEACAM6\", pt.size = 0) +\n  NoLegend()\n\n\n\n\n\n\n\n\nWe see that clusters 1 and 10 do indeed have higher expression of this tumor marker gene! We can even look at CEACAM5 at the same time with a dotplot to gain more confidence with two marker genes as well:\n\nDotPlot(seurat_processed, c(\"CEACAM5\", \"CEACAM6\"))\n\n\n\n\n\n\n\n\nNow we also have the additional knowledge that there are likely some tumor cells among cluster 7."
  },
  {
    "objectID": "lessons/07_integration.html#final-integration-decision",
    "href": "lessons/07_integration.html#final-integration-decision",
    "title": "Integration",
    "section": "Final Integration Decision",
    "text": "Final Integration Decision\nWe can see that the lack of overlap in samples/batch have a biological answer, it would not make sense to try and force the cells together using integration. If we were to try and integrate the dataset at this point, we would be trying to massage the tumor cells to appear more similarly to other populations in the dataset. That is not the end goal of our analysis, where we would want to identify the difference transcriptional differences in tumor cells.\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1"
  },
  {
    "objectID": "lessons/07_integration_Answer-key.html",
    "href": "lessons/07_integration_Answer-key.html",
    "title": "Integration Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html",
    "href": "lessons/08_spatially_derived_clusters.html",
    "title": "Spatially Derived Clusters",
    "section": "",
    "text": "Approximate time: XY minutes"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#sub-topic-1",
    "href": "lessons/08_spatially_derived_clusters.html#sub-topic-1",
    "title": "Spatially Derived Clusters",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#sub-topic-2",
    "href": "lessons/08_spatially_derived_clusters.html#sub-topic-2",
    "title": "Spatially Derived Clusters",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#sub-topic-3",
    "href": "lessons/08_spatially_derived_clusters.html#sub-topic-3",
    "title": "Spatially Derived Clusters",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#sub-topic-1-1",
    "href": "lessons/08_spatially_derived_clusters.html#sub-topic-1-1",
    "title": "Spatially Derived Clusters",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#sub-topic-2-1",
    "href": "lessons/08_spatially_derived_clusters.html#sub-topic-2-1",
    "title": "Spatially Derived Clusters",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#sub-topic-3-1",
    "href": "lessons/08_spatially_derived_clusters.html#sub-topic-3-1",
    "title": "Spatially Derived Clusters",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 1"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#sub-topic-1-2",
    "href": "lessons/08_spatially_derived_clusters.html#sub-topic-1-2",
    "title": "Spatially Derived Clusters",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#sub-topic-2-2",
    "href": "lessons/08_spatially_derived_clusters.html#sub-topic-2-2",
    "title": "Spatially Derived Clusters",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#sub-topic-3-2",
    "href": "lessons/08_spatially_derived_clusters.html#sub-topic-3-2",
    "title": "Spatially Derived Clusters",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3\n\n\n\n\n\n\nExercise 3\n\n\n\nExercise 3"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters_Answer-key.html",
    "href": "lessons/08_spatially_derived_clusters_Answer-key.html",
    "title": "Spatially Derived Clusters Answer Key",
    "section": "",
    "text": "Exercise 1\nQuestion\nAnswer\n\n\nExercise 2\nQuestion\nAnswer\n\n\nExercise 3\nQuestion\nAnswer"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#set-up",
    "href": "lessons/08_spatially_derived_clusters.html#set-up",
    "title": "Spatially Derived Clusters",
    "section": "Set-up",
    "text": "Set-up\nWe use the RunBanksy function to create a new “BANKSY” assay based on a default of the 4,000 most highly variable features, which can be used for dimensionality reduction and clustering. Some parameters of importance are:\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\nk_geom\nNumber of bins to consider for the local neighborhood. Larger values will yield larger domains.\n\n\nlambda\nInfluence of the neighborhood. Larger values yield more spatially coherent domains. The authors recommend using 0.8 to identify broader spatial domains.\n\n\ngroup\nAllows us to run BANKSY on multiple samples, enabling the function to understand that overlapping spatial locations can come from different slides.\n\n\ndimx, dimy\nThe x and y coordinates of a spot on the tissue slide.\n\n\nsplit.scale\nWithin-group scaling parameter, accounting for minor differences between datasets.\n\n\n\nTo set ourselves up for success, we are going to add the spatial locations for each spot into the metadata. This will allow us to specify dimx and dimy more easily.\n\nseurat_processed$cell &lt;- rownames(seurat_processed@meta.data)\n# CRC and NAT sample coordinates\ncoords_crc &lt;- GetTissueCoordinates(seurat_processed, image = \"P5CRC.008um\")\ncoords_nat &lt;- GetTissueCoordinates(seurat_processed, image = \"P5NAT.008um\")\ncoords &lt;- rbind(coords_crc, coords_nat)\n\nseurat_processed@meta.data &lt;- left_join(seurat_processed@meta.data, coords, by = \"cell\")\nrownames(seurat_processed@meta.data) &lt;- seurat_processed$cell\n\nWhich we can now use to calculate the new BANKSY matrix. This step can take a while to compute (TODO time estimate)\n\n# Run Banksy from SeuratWrappers\nseurat_banksy &lt;- RunBanksy(seurat_processed, lambda = 0.8, verbose = T,\n                           assay = 'Spatial.008um', slot = 'data', k_geom = 50,\n                           group = \"orig.ident\", dimx = 'x', dimy = 'y', \n                           split.scale = TRUE)\n\nWith a new Active assay: BANKSY\n\nseurat_banksy\n\nAn object of class Seurat \n40170 features across 826613 samples within 3 assays \nActive assay: BANKSY (4000 features, 0 variable features)\n 2 layers present: data, scale.data\n 2 other assays present: Spatial.008um, sketch\n 4 dimensional reductions calculated: pca.sketch, umap.sketch, full.pca.sketch, full.umap.sketch\n 2 spatial fields of view present: P5CRC.008um P5NAT.008um"
  },
  {
    "objectID": "lessons/Pre-reading_01.html#advantages",
    "href": "lessons/Pre-reading_01.html#advantages",
    "title": "Spatial Technologies",
    "section": "Advantages",
    "text": "Advantages\nAnalyses that make use of many genes at once (functional analysis, RNA velocity, etc.) can be done on these datasets.\nCan be run on non-model organisms with more ease.",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#disadvantage",
    "href": "lessons/Pre-reading_01.html#disadvantage",
    "title": "Spatial Technologies",
    "section": "Disadvantage",
    "text": "Disadvantage\nHigh resolution experiments (Visium HD) can be very expensive",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#summary-of-current-methods",
    "href": "lessons/Pre-reading_01.html#summary-of-current-methods",
    "title": "Spatial Technologies",
    "section": "Summary of Current Methods",
    "text": "Summary of Current Methods\nVisium GeoMX",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#advantages-1",
    "href": "lessons/Pre-reading_01.html#advantages-1",
    "title": "Spatial Technologies",
    "section": "Advantages",
    "text": "Advantages\nAs imaging the slide is the foremost part of the method, you are able to annotate subregions of the tissue on a more granular level.",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#disadvantages",
    "href": "lessons/Pre-reading_01.html#disadvantages",
    "title": "Spatial Technologies",
    "section": "Disadvantages",
    "text": "Disadvantages\nAs this is a probe-based method, there must be known probes for each gene of interest. This can be particularly challenging for non-model organisms and limits the scale of expression for each cell.",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/Pre-reading_01.html#summary-of-current-methods-1",
    "href": "lessons/Pre-reading_01.html#summary-of-current-methods-1",
    "title": "Spatial Technologies",
    "section": "Summary of Current Methods",
    "text": "Summary of Current Methods\nseqFISH MERFISH Xenium",
    "crumbs": [
      "Pre-reading:",
      "Spatial Technologies"
    ]
  },
  {
    "objectID": "lessons/spatial_technology_overview.html",
    "href": "lessons/spatial_technology_overview.html",
    "title": "Spatial Technologies",
    "section": "",
    "text": "Approximate time: XY minutes"
  },
  {
    "objectID": "lessons/spatial_technology_overview.html#sub-topic-1",
    "href": "lessons/spatial_technology_overview.html#sub-topic-1",
    "title": "Spatial Technologies",
    "section": "Sub-topic 1",
    "text": "Sub-topic 1"
  },
  {
    "objectID": "lessons/spatial_technology_overview.html#sub-topic-2",
    "href": "lessons/spatial_technology_overview.html#sub-topic-2",
    "title": "Spatial Technologies",
    "section": "Sub-topic 2",
    "text": "Sub-topic 2"
  },
  {
    "objectID": "lessons/spatial_technology_overview.html#sub-topic-3",
    "href": "lessons/spatial_technology_overview.html#sub-topic-3",
    "title": "Spatial Technologies",
    "section": "Sub-topic 3",
    "text": "Sub-topic 3"
  },
  {
    "objectID": "lessons/spatial_technology_overview.html#advantages",
    "href": "lessons/spatial_technology_overview.html#advantages",
    "title": "Spatial Technologies",
    "section": "Advantages",
    "text": "Advantages\nAnalyses that make use of many genes at once (functional analysis, RNA velocity, etc.) can be done on these datasets.\nCan be run on non-model organisms with more ease."
  },
  {
    "objectID": "lessons/spatial_technology_overview.html#disadvantage",
    "href": "lessons/spatial_technology_overview.html#disadvantage",
    "title": "Spatial Technologies",
    "section": "Disadvantage",
    "text": "Disadvantage\nHigh resolution experiments (Visium HD) can be very expensive"
  },
  {
    "objectID": "lessons/spatial_technology_overview.html#summary-of-current-methods",
    "href": "lessons/spatial_technology_overview.html#summary-of-current-methods",
    "title": "Spatial Technologies",
    "section": "Summary of Current Methods",
    "text": "Summary of Current Methods\nVisium GeoMX"
  },
  {
    "objectID": "lessons/spatial_technology_overview.html#advantages-1",
    "href": "lessons/spatial_technology_overview.html#advantages-1",
    "title": "Spatial Technologies",
    "section": "Advantages",
    "text": "Advantages\nAs imaging the slide is the foremost part of the method, you are able to annotate subregions of the tissue on a more granular level."
  },
  {
    "objectID": "lessons/spatial_technology_overview.html#disadvantages",
    "href": "lessons/spatial_technology_overview.html#disadvantages",
    "title": "Spatial Technologies",
    "section": "Disadvantages",
    "text": "Disadvantages\nAs this is a probe-based method, there must be known probes for each gene of interest. This can be particularly challenging for non-model organisms and limits the scale of expression for each cell."
  },
  {
    "objectID": "lessons/spatial_technology_overview.html#summary-of-current-methods-1",
    "href": "lessons/spatial_technology_overview.html#summary-of-current-methods-1",
    "title": "Spatial Technologies",
    "section": "Summary of Current Methods",
    "text": "Summary of Current Methods\nseqFISH MERFISH Xenium"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#new-banksy-matrix",
    "href": "lessons/08_spatially_derived_clusters.html#new-banksy-matrix",
    "title": "Spatially Derived Clusters",
    "section": "New BANKSY Matrix",
    "text": "New BANKSY Matrix\nAt this point, we have our new counts matrix that includes our neighborhood weighted scores. We can see this more clearly if we investigate the Features() that exist in our BANKSY assay. Where teh first few features are our original counts matrix with genes\n\nFeatures(seurat_banksy) %&gt;% head()\n\n[1] \"IGHG3\" \"IGHM\"  \"SPP1\"  \"IGLC7\" \"IGLC1\" \"SST\"  \n\n\nWhere we also have “new genes” that are our lambda scaled neighborhood weighted values, with an appended *.m0 to make the distinction clear.\n\nFeatures(seurat_banksy) %&gt;% tail()\n\n[1] \"CD6.m0\"    \"C1QBP.m0\"  \"CHL1.m0\"   \"PRSS8.m0\"  \"MTCH2.m0\"  \"THSD7A.m0\""
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#calculation-on-banksy-matrix",
    "href": "lessons/08_spatially_derived_clusters.html#calculation-on-banksy-matrix",
    "title": "Spatially Derived Clusters",
    "section": "Calculation on BANKSY Matrix",
    "text": "Calculation on BANKSY Matrix\nWith these weights, we can now run through a simplified clustering workflow - using many of the same functions we used in the previous lesson on the scRNA workflow. The only distinction here is that these values are going to be calculated on our new BANKSY count matrix.\n\n# Increases the size of the default vector\noptions(future.globals.maxSize= 200000000000)\n\n# PCA\nseurat_banksy &lt;- RunPCA(seurat_banksy, \n                        assay = \"BANKSY\", \n                        reduction.name = \"pca.banksy\", \n                        features = rownames(seurat_banksy), \n                        npcs = 30)\n# Find k-Nearest Neighbors\nseurat_banksy &lt;- FindNeighbors(seurat_banksy, \n                               reduction = \"pca.banksy\", \n                               dims = 1:30)\n# Louvain clustering\nseurat_banksy &lt;- FindClusters(seurat_banksy, \n                              cluster.name = \"banksy_cluster\",\n                              resolution = 0.5)\n\nAt this point, we no longer need access to the BANKSY assay as all the relevant information has now been stored as:\n\nbanksy_clusters in @meta.data\npca.banksy in @reductions\n\nSo to conserve memory, we are going to delete the BANKSY assay from our seurat object.\n\n# Change default asasy from BANKSY\nDefaultAssay(seurat_banksy) &lt;- \"Spatial.008um\"\n\n# Delete BANKSY assay by setting it to NULL\nseurat_banksy[[\"BANKSY\"]] &lt;- NULL\n\n\n\n\n\n\n\nExercise 2\n\n\n\nExercise 1"
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#use-case-of-svgs",
    "href": "lessons/08_spatially_derived_clusters.html#use-case-of-svgs",
    "title": "Spatially Derived Clusters",
    "section": "Use Case of SVGs",
    "text": "Use Case of SVGs\nhttps://www.nature.com/articles/s41467-025-56080-w\n\nMethods for detecting the three SVG categories serve different purposes (Fig. 2a). First, the detection of overall SVGs screens informative genes for downstream analyses, including the identification of spatial domains and functional gene modules. Second, detecting cell-type-specific SVGs aims to reveal spatial variation within a cell type and help identify distinct cell subpopulations or states within cell types. Third, spatial-domain-marker SVG detection is used to find marker genes to annotate and interpret spatial domains already detected. These markers help understand the molecular mechanisms underlying spatial domains and assist in annotating tissue layers in other datasets."
  },
  {
    "objectID": "lessons/08_spatially_derived_clusters.html#methods",
    "href": "lessons/08_spatially_derived_clusters.html#methods",
    "title": "Spatially Derived Clusters",
    "section": "Methods",
    "text": "Methods\n\nSpatialDE (python)\nMERINGUE\nBinSpect"
  },
  {
    "objectID": "lessons/03_quality-control.html#spatial-overlay-4",
    "href": "lessons/03_quality-control.html#spatial-overlay-4",
    "title": "Quality Control",
    "section": "Spatial Overlay",
    "text": "Spatial Overlay\nNext, we can look at the same metrics and the distribution on the actual image itself. Note that many spots have very few counts, in part due to low cellular density or cell types with low complexity in certain tissue regions.\n\nSpatialFeaturePlot(seurat_filtered, \n                   c(\"nFeature_Spatial.008um\", \"nCount_Spatial.008um\"),\n                   pt.size.factor = 3,\n                   image.alpha = 0)\n\n\n\n\n\n\n\nFigure 16: Number of features and counts overlaid over spatial slide",
    "crumbs": [
      "Day 1 Self-learning:",
      "Quality Control"
    ]
  }
]